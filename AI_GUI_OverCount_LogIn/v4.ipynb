{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "94024bfa64e14908a1ff5a59a1df94ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a37f7f31d904a848135203eb226528c",
              "IPY_MODEL_1b57b6f30f1c46bea37a49a1176509c8",
              "IPY_MODEL_5fcba14869844d4f906a24fc5d3ef66e"
            ],
            "layout": "IPY_MODEL_d3b901034a554594a971e43afe4477da"
          }
        },
        "1a37f7f31d904a848135203eb226528c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b76517783e9a4eb0870c67f895baa7c8",
            "placeholder": "​",
            "style": "IPY_MODEL_74be042770294ac78c4fa05ec222b12a",
            "value": "Fetching 17 files: 100%"
          }
        },
        "1b57b6f30f1c46bea37a49a1176509c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6f03490524049649a267bc011d456b3",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d49ba940452e48c39662fe956cf4c9d1",
            "value": 17
          }
        },
        "5fcba14869844d4f906a24fc5d3ef66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41922f82b02f4808890bcba1ab59f1b4",
            "placeholder": "​",
            "style": "IPY_MODEL_f44e63db6d7849aa8b676d673a5f5d0c",
            "value": " 17/17 [00:00&lt;00:00, 1778.36it/s]"
          }
        },
        "d3b901034a554594a971e43afe4477da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b76517783e9a4eb0870c67f895baa7c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74be042770294ac78c4fa05ec222b12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6f03490524049649a267bc011d456b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d49ba940452e48c39662fe956cf4c9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41922f82b02f4808890bcba1ab59f1b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44e63db6d7849aa8b676d673a5f5d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28673ebfa2dc4ee58fd4a840b0b76394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f02754743a143549514f8e11e4b2276",
              "IPY_MODEL_4d4895f81370407a995301aec7fc5eb4",
              "IPY_MODEL_0f1d5725e87649e0ac5f2da8606392f8"
            ],
            "layout": "IPY_MODEL_19d391e67f774800bb6c9d00561ce58c"
          }
        },
        "2f02754743a143549514f8e11e4b2276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6bac83332a2486183acb11abec8bfb4",
            "placeholder": "​",
            "style": "IPY_MODEL_d1edeaa5a70d4f47816a850d8bfa8011",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "4d4895f81370407a995301aec7fc5eb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba67880970fc4f26b65cd6969be4b72d",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dccc9ccabdd04208a36eb4456bb24f14",
            "value": 7
          }
        },
        "0f1d5725e87649e0ac5f2da8606392f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85c502c645184af491fd74902507c067",
            "placeholder": "​",
            "style": "IPY_MODEL_0b85282b86574c14917398c35706efab",
            "value": " 7/7 [00:03&lt;00:00,  1.54it/s]"
          }
        },
        "19d391e67f774800bb6c9d00561ce58c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6bac83332a2486183acb11abec8bfb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1edeaa5a70d4f47816a850d8bfa8011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba67880970fc4f26b65cd6969be4b72d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccc9ccabdd04208a36eb4456bb24f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85c502c645184af491fd74902507c067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b85282b86574c14917398c35706efab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "359ae9d616344197967347bed899a22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09a3f99d2a9b49918f8047b69aa4a88a",
              "IPY_MODEL_c75b7c49868f405484b627f7324dda80",
              "IPY_MODEL_01327d8e22d64d4b99d11944920a86d0"
            ],
            "layout": "IPY_MODEL_272c9367d3c346eca935868c37e54bf9"
          }
        },
        "09a3f99d2a9b49918f8047b69aa4a88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8be9ea0c49914e09b21b26ba5e62e659",
            "placeholder": "​",
            "style": "IPY_MODEL_d9e2fb87b0334d6da36f1bf944854213",
            "value": "100%"
          }
        },
        "c75b7c49868f405484b627f7324dda80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9217ee429474da695799e014b30a0f1",
            "max": 60,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_563e14fdb6084959b8e6c61fdfebbf0f",
            "value": 60
          }
        },
        "01327d8e22d64d4b99d11944920a86d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcee30c2bd604805a111a29f126b588f",
            "placeholder": "​",
            "style": "IPY_MODEL_a243fdced40e4ddd9d2c45e0cd333510",
            "value": " 60/60 [00:22&lt;00:00,  2.69it/s]"
          }
        },
        "272c9367d3c346eca935868c37e54bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8be9ea0c49914e09b21b26ba5e62e659": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9e2fb87b0334d6da36f1bf944854213": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9217ee429474da695799e014b30a0f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563e14fdb6084959b8e6c61fdfebbf0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dcee30c2bd604805a111a29f126b588f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a243fdced40e4ddd9d2c45e0cd333510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T2718/AI_Make_Image/blob/main/AI_GUI_OverCount_LogIn/v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Driveのマウント\n",
        "#@markdown **Driveを使用する場合はチェックを入れて実行**\n",
        "drive_use = True #@param {type:\"boolean\"}\n",
        "mount_point = '/content/drive'\n",
        "\n",
        "#drive_use = Drive_path.strip() != \"\"\n",
        "if drive_use:\n",
        "  from google.colab import drive\n",
        "  import os\n",
        "  if not os.path.exists(mount_point):\n",
        "    drive.mount(mount_point)\n",
        "  if not os.path.exists(mount_point):\n",
        "    drive_use = False\n",
        "    print(\"Google Driveに接続できません。\")"
      ],
      "metadata": {
        "id": "asc2tF_Tn5wz",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1c177a-a4f9-4c9c-96ec-adf4e4aa3a12"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown model_path_listを定義\n",
        "from pathlib import Path\n",
        "\n",
        "list_path = \"/content/drive/MyDrive/Colab Notebooks/share_dir/AI_IMG/modelPathList.txt\" #@param {type:\"string\"}\n",
        "list_path = Path(list_path)\n",
        "\n",
        "model_path_list = {}\n",
        "explain_map = {}\n",
        "\n",
        "with list_path.open(encoding=\"utf-8\") as f:\n",
        "    current_name = None\n",
        "    for line in f:\n",
        "        line = line.rstrip()  # 行末の空白だけ削除\n",
        "        if not line:\n",
        "            continue\n",
        "        if line.startswith(\" - [LogIn]\"):  # 行頭の空白+ハイフン+空白+[LogIn]のみ判定\n",
        "            if current_name:\n",
        "                explain_map[current_name] = line\n",
        "            continue\n",
        "        if \":\" in line:\n",
        "            name, url = line.split(\":\", 1)\n",
        "            current_name = name.strip()\n",
        "            model_path_list[current_name] = url.strip()\n",
        "\n",
        "# 見やすく出力（- [LogIn] のみ赤字）\n",
        "print(\"model_path_list = {\")\n",
        "for k, v in model_path_list.items():\n",
        "    explain = explain_map.get(k, \"\")\n",
        "    if explain.startswith(\" - [LogIn]\"):  # 条件に合うものだけ赤字\n",
        "        k_disp = f\"\\033[31m{k}\\033[0m\"\n",
        "    else:\n",
        "        k_disp = k\n",
        "    print(f'    \"{k_disp}\": \"{v}\",')\n",
        "print(\"}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPbAud0rQLGN",
        "outputId": "54aa856f-8906-4149-bce2-2b665c6ae4ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_path_list = {\n",
            "    \"\u001b[31mAgeless-v2\u001b[0m\": \"https://civitai.com/api/download/models/74004?type=Model&format=SafeTensor&size=full&fp=fp16\",\n",
            "    \"Animagine_XL-4.0\": \"https://civitai.com/api/download/models/1408658?type=Model&format=SafeTensor&size=full&fp=fp16\",\n",
            "    \"Hassaku_XL-v3.0_WIP\": \"https://civitai.com/api/download/models/2010753?type=Model&format=SafeTensor&size=pruned&fp=fp16\",\n",
            "    \"\u001b[31mmilktea-v3_typeB\u001b[0m\": \"https://civitai.com/api/download/models/592037?type=Model&format=SafeTensor&size=pruned&fp=fp16\",\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 変数の設定\n",
        "#@markdown Google Driveに生成した画像を保存したい場合は<br>\n",
        "#@markdown そのディレクトリのパスを入力。\n",
        "#@markdown <br>Driveを使用しない際は空欄のまま<br>\n",
        "#@markdown (例:/content/drive/MyDrive/Colab Notebooks/Generated_IMG)\n",
        "Drive_path = \"/content/drive/MyDrive/Colab Notebooks/share_dir/AI_IMG/generated\" #@param {type:\"string\"}\n",
        "#drive_use = Drive_path.strip() != \"\"\n",
        "if drive_use:\n",
        "  drive_save = Drive_path\n",
        "else:\n",
        "  drive_save = \"\"\n",
        "#@markdown ##種類\n",
        "#@markdown 1. **Hugging Face**\n",
        "#@markdown 2. **CivitAI**<br>\n",
        "#@markdown    [1,2について]Text to ImageまたはImage to Imageを<br>\n",
        "#@markdown    行うためのモデルの種類<br>\n",
        "#@markdown    **.safetensorsファイルを使用する際はHugging FaceでもCivitAIを選択！**<br>\n",
        "#@markdown    例えば、Hugging Faceの<br>\n",
        "#@markdown    eimiss/EimisAnimeDiffusion_2.0v<br>*https://huggingface.co/eimiss/EimisAnimeDiffusion_2.0v/resolve/main/EimisModel_2-0.safetensors?download=true*\n",
        "#@markdown 3. **Resize&補完**#@markdown    元画像Pathに入れた、対応する画像をリサイズし、\n",
        "#@markdown.   余白の部分を補完する。\n",
        "#@markdown 4. **トークン数確認**\n",
        "#@markdown   文のトークン数を確認できる。\n",
        "#@markdown 5. **ダウンロード**\n",
        "#@markdown 6. **削除**<br>\n",
        "#@markdown   [4,5について]<small>*※Google Driveを使わずに画像生成した場合のみ有効*</small><br>\n",
        "#@markdown   /content/downloadディレクトリを.zipでダウンロード<br>\n",
        "#@markdown   または削除\n",
        "#@markdown 7. **初期値**<br>\n",
        "#@markdown   フォームの値の初期値を表示<br>\n",
        "#@markdown   <small>ただし、フォームの値は置き換わりません。</small>\n",
        "Kind = \"CivitAI\" #@param [\"Hugging Face\",\"CivitAI\",\"Resize&補完\",\"Token数確認\",\"ダウンロード\",\"削除\",\"初期値\"]\n",
        "#@markdown ***以下、括弧()内に種類の番号ごとの入力必須の欄を指定***\n",
        "#@markdown ##削除orダウンロードするパス (5,6)<br>\n",
        "#@markdown 削除またはダウンロードするディレクトリのパス\n",
        "DirPath = \"/content/drive/MyDrive/Colab Notebooks/share_dir/AI_IMG/generated/GoodIMG/無題107_20250527013049.png\" #@param {type:\"string\"}\n",
        "#@markdown ##Text to Image(t2i)かImage to Image(i2i) (1,2)\n",
        "SubMode = \"t2i\" #@param [\"t2i\",\"i2i\"]\n",
        "#@markdown ##ポジティブプロンプト (1,2,3,4)\n",
        "Positive_Prompt = \"1girl,solo,looking at viewer,standing,upper body,double v,teeth,smile,<lora:cunnyfunkystyle2:1>,cunnyfunkystyle,\" #@param {type:\"string\"}\n",
        "#@markdown ##ネガティブプロンプト (1,2,3)\n",
        "Negative_Prompt = \"\" #@param {type:\"string\"}\n",
        "#@markdown ##枚数 (1,2,3)\n",
        "Num = 15 #@param {type:\"number\"}\n",
        "#@markdown ##Step (1,2,3)\n",
        "Steps = 60 #@param {type:\"number\"}\n",
        "#@markdown ##Width,Height (1,2,3)\n",
        "#@markdown - <small>*[1,2]のi2iの場合において、元画像のサイズで*</small><br>\n",
        "#@markdown   <small>*生成する場合はチェックを入れてください。*</small>\n",
        "OriginSize = True #@param {type:\"boolean\"}\n",
        "#@markdown **どちらも8の倍数**で\n",
        "Width = 768 #@param {type:\"number\"}\n",
        "Height = 512 #@param {type:\"number\"}\n",
        "#@markdown ##画像のPath ([1,2]のi2i,3)\n",
        "ImagePath = \"/content/drive/MyDrive/Colab Notebooks/share_dir/AI_IMG/generated/GoodIMG/Used_card/2 (1)-86x54.jpg\" #@param {type:\"string\"}\n",
        "#@markdown ##画像からの変化の強度(0~1の間) ([1,2]のi2i,3)\n",
        "Strength = 0.8 #@param {type:\"number\"}\n",
        "#@markdown ##MaskのPath (3)\n",
        "MaskPath = \"/content/mask 5.png\" #@param {type:\"string\"}\n",
        "#@markdown ##プロンプトに従う強度 (1,2)\n",
        "Guidance = 9 #@param {type:\"number\"}\n",
        "#@markdown ##モデルの状況 (2,3)\n",
        "#@markdown - **none** インストールもしていない。\n",
        "#@markdown - **origin** インストールはしているが<br>\n",
        "#@markdown   変換はしていない。\n",
        "#@markdown - **complete** 変換も済んでいる。そのまま使える。\n",
        "Model_Status = \"none\" #@param [\"none\",\"origin\",\"complete\"]\n",
        "#@markdown ##Modelの種類<br>\n",
        "#@markdown *(**1(=Hugging Face)**,2・3で先程の解答がnoneまたはoriginの時)*\n",
        "#@markdown - 1(=Hugging Face)\n",
        "#@markdown   - モデルの種類<br>\n",
        "#@markdown     <small>以下、例</small>\n",
        "#@markdown     - gsdf/Counterfeit-V3.0\n",
        "#@markdown     - stablediffusionapi/eleet-model\n",
        "#@markdown     - stablediffusionapi/brav6\n",
        "#@markdown     - Vsukiyaki/ShiratakiMix\n",
        "#@markdown     - stabilityai/stable-diffusion-xl-base-1.0\n",
        "#@markdown - 2(=CivitAI)・3で、先程のモデルの状況で<br>\n",
        "#@markdown   noneまたはoriginを選択した場合。<br>\n",
        "#@markdown   <small>以下のどれかに従って入力。</small>\n",
        "#@markdown   - 特定の数字を入力\n",
        "#@markdown     1. Anime Pastel Dream<br>\n",
        "#@markdown     <small>(SDXL:False,NeedYaml:False)</small>\n",
        "#@markdown     2. WAI-NSFW-illustrious-SDXL v:11.0<br>\n",
        "#@markdown     <small>(SDXL:True,NeedYaml:True)</small>\n",
        "#@markdown   - \\#◯◯◯◯(数字)<br>\n",
        "#@markdown     Model ID\n",
        "#@markdown   - CivitAIモデルのURL(https:~~)\n",
        "#@markdown   更に、この2つ後の欄(.yaml)も選択必須\n",
        "Model = \"2\" #@param {type:\"string\"}\n",
        "#@markdown ##SDXLかどうか (2,3)\n",
        "#@markdown ***'NoneType' object has no attribute 'tokenize'*<br>\n",
        "#@markdown エラーが出た場合は、SDXLでない可能性があります。**\n",
        "Sdxl = True #@param {type:\"boolean\"}\n",
        "#@markdown ##.yamlファイルが必要かどうか([2,3]のSDXL)\n",
        "#@markdown 三つ前の解答がnoneまたはoriginで、<br>\n",
        "#@markdown SDXLである場合、選択必須<br>\n",
        "#@markdown <small>Modelの.safetensorsに.yamlファイルが<br>\n",
        "#@markdown 使用されていない場合必要。<br>\n",
        "#@markdown 迷ったら入れてみよう。</small>\n",
        "NeedYaml = True #@param {type:\"boolean\"}\n",
        "#@markdown ##Pipelineをインストールするか(1,2,3)<br>\n",
        "#@markdown **3の時はgeneratorをインストールするか**<br>\n",
        "#@markdown ###以下の時はインストールする必要があります。<br>\n",
        "#@markdown ###基本的に、続けて画像生成を行う際には必要ありません。\n",
        "#@markdown - モデルの更新を行った時(インストールor変換)\n",
        "#@markdown - 現セッションで初の生成の時\n",
        "#@markdown - t2iまたはi2iでPipelineをインストール後、<br>\n",
        "#@markdown   もう一方に切り替えて生成を行う時\n",
        "PipeInstall = True #@param {type:\"boolean\"}\n",
        "#@markdown ##ライブラリのインストールをするか<br>\n",
        "#@markdown 現セッション内で一度でも[1,2,3]のどれかを<br>\n",
        "#@markdown 実行した場合はライブラリのインストールが必要ありません。\n",
        "NeedInstall = False #@param {type:\"boolean\"}\n",
        "#@markdown ##Loraのパス(1,2)\n",
        "#@markdown 使用する際はmodelのURLを入力。\n",
        "#@markdown 使用しない場合は空欄のまま\n",
        "LoraPath = \"https://civitai.com/api/download/models/1709991?type=Model&format=SafeTensor\" #@param {type:\"string\"}\n",
        "#@markdown ##別のモデルパスを指定 (origin, complete)\n",
        "#@markdown originまたはcompleteで、別のパスからモデルを読み込みたい場合に指定。\n",
        "#@markdown 空欄の場合はデフォルトのパスを使用。\n",
        "Model_Insert_Path = \"https://civitai.com/api/download/models/2167369?type=Model&format=SafeTensor&size=pruned&fp=fp16\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "#変数の変換 ------------------------------\n",
        "\n",
        "\n",
        "# --- Drive設定 ---\n",
        "#drive_use = Drive_path.strip() != \"\"\n",
        "\n",
        "# --- モードを番号に変換 ---\n",
        "mode = (\n",
        "  \"1\" if Kind == \"Hugging Face\"\n",
        "  else \"2\" if Kind == \"CivitAI\"\n",
        "  else \"3\" if Kind == \"Resize&補完\"\n",
        "  else \"4\" if Kind == \"Token数確認\"\n",
        "  else \"5\" if Kind == \"ダウンロード\"\n",
        "  else \"6\" if Kind == \"削除\"\n",
        "  else \"7\" if Kind == \"初期値\"\n",
        "  else \"\"\n",
        ")\n",
        "\n",
        "# --- パラメータ辞書の初期化 ---\n",
        "hf_params = {}\n",
        "civitai_params = {}\n",
        "\n",
        "# --- Hugging Face ---\n",
        "if mode == \"1\":\n",
        "  hf_params = {\n",
        "    \"need_pipe\": PipeInstall,\n",
        "    \"model_id\": Model,\n",
        "    \"submode\": \"2\" if SubMode == \"i2i\" else \"1\",\n",
        "    \"positive_prompt\": Positive_Prompt,\n",
        "    \"negative_prompt\": Negative_Prompt,\n",
        "    \"num\": Num,\n",
        "    \"steps\": Steps,\n",
        "    \"guidance\": Guidance\n",
        "  }\n",
        "  if SubMode == \"i2i\":\n",
        "    hf_params[\"strength\"] = Strength\n",
        "    hf_params[\"image_path\"] = ImagePath\n",
        "\n",
        "# --- CivitAI ---\n",
        "elif mode == \"2\":\n",
        "  Model_After = Model\n",
        "  if Model.startswith(\"List:\"):\n",
        "    Model_After = model_path_list[Model[5:]]\n",
        "\n",
        "  civitai_params = {\n",
        "    \"status\": (\n",
        "      \"1\" if Model_Status == \"none\"\n",
        "      else \"2\" if Model_Status == \"origin\"\n",
        "      else \"3\"\n",
        "    ),\n",
        "    \"sdxl\": Sdxl,\n",
        "    \"need_yaml\": NeedYaml,\n",
        "    #\"need_yaml\": (Model_Status in [\"none\", \"origin\"] and Sdxl),\n",
        "    \"need_pipe\": PipeInstall,\n",
        "    \"submode\": \"2\" if SubMode == \"i2i\" else \"1\",\n",
        "    \"positive_prompt\": Positive_Prompt,\n",
        "    \"negative_prompt\": Negative_Prompt,\n",
        "    \"num\": Num,\n",
        "    \"steps\": Steps,\n",
        "    \"guidance\": Guidance,\n",
        "    \"url\": Model_After,\n",
        "    \"lora_path\": LoraPath.strip() if LoraPath.strip() else None,\n",
        "    \"model_insert_path\": Model_Insert_Path.strip() if Model_Insert_Path.strip() else None\n",
        "  }\n",
        "  if SubMode == \"i2i\":\n",
        "    civitai_params[\"strength\"] = Strength\n",
        "    civitai_params[\"image_path\"] = ImagePath\n",
        "\n",
        "elif mode == \"3\":\n",
        "  resize_params = {\n",
        "    \"status\": (\n",
        "      \"1\" if Model_Status == \"none\"\n",
        "      else \"2\" if Model_Status == \"origin\"\n",
        "      else \"3\"\n",
        "    ),\n",
        "    \"sdxl\": Sdxl,\n",
        "    \"need_yaml\": NeedYaml,\n",
        "    #\"need_yaml\": (Model_Status in [\"none\", \"origin\"] and Sdxl),\n",
        "    \"need_pipe\": PipeInstall,\n",
        "    \"submode\": \"2\" if SubMode == \"i2i\" else \"1\",\n",
        "    \"positive_prompt\": Positive_Prompt,\n",
        "    \"negative_prompt\": Negative_Prompt,\n",
        "    \"num\": Num,\n",
        "    \"steps\": Steps,\n",
        "    \"url\": Model,\n",
        "    \"strength\" : Strength,\n",
        "    \"image_path\" : ImagePath,\n",
        "    \"mask_path\" : MaskPath,\n",
        "    \"install_tf\" : PipeInstall,\n",
        "    \"model_insert_path\": Model_Insert_Path.strip() if Model_Insert_Path.strip() else None\n",
        "  }\n",
        "\n",
        "# --- Token数確認 ---\n",
        "elif mode == \"4\":\n",
        "  token_prompt = Positive_Prompt"
      ],
      "metadata": {
        "id": "C_U6Xe4gbkfL",
        "cellView": "form"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "94024bfa64e14908a1ff5a59a1df94ee",
            "1a37f7f31d904a848135203eb226528c",
            "1b57b6f30f1c46bea37a49a1176509c8",
            "5fcba14869844d4f906a24fc5d3ef66e",
            "d3b901034a554594a971e43afe4477da",
            "b76517783e9a4eb0870c67f895baa7c8",
            "74be042770294ac78c4fa05ec222b12a",
            "a6f03490524049649a267bc011d456b3",
            "d49ba940452e48c39662fe956cf4c9d1",
            "41922f82b02f4808890bcba1ab59f1b4",
            "f44e63db6d7849aa8b676d673a5f5d0c",
            "28673ebfa2dc4ee58fd4a840b0b76394",
            "2f02754743a143549514f8e11e4b2276",
            "4d4895f81370407a995301aec7fc5eb4",
            "0f1d5725e87649e0ac5f2da8606392f8",
            "19d391e67f774800bb6c9d00561ce58c",
            "a6bac83332a2486183acb11abec8bfb4",
            "d1edeaa5a70d4f47816a850d8bfa8011",
            "ba67880970fc4f26b65cd6969be4b72d",
            "dccc9ccabdd04208a36eb4456bb24f14",
            "85c502c645184af491fd74902507c067",
            "0b85282b86574c14917398c35706efab",
            "359ae9d616344197967347bed899a22f",
            "09a3f99d2a9b49918f8047b69aa4a88a",
            "c75b7c49868f405484b627f7324dda80",
            "01327d8e22d64d4b99d11944920a86d0",
            "272c9367d3c346eca935868c37e54bf9",
            "8be9ea0c49914e09b21b26ba5e62e659",
            "d9e2fb87b0334d6da36f1bf944854213",
            "b9217ee429474da695799e014b30a0f1",
            "563e14fdb6084959b8e6c61fdfebbf0f",
            "dcee30c2bd604805a111a29f126b588f",
            "a243fdced40e4ddd9d2c45e0cd333510"
          ]
        },
        "cellView": "form",
        "id": "f2bc6b1d",
        "outputId": "feea6f02-d12f-44e5-880a-057bd19841f7"
      },
      "source": [
        "#@title 実行する\n",
        "#@markdown ##初回はライブラリのインストールに時間がかかります。<br>\n",
        "#@markdown **特に、Kindが「1」または「2」での初回の実行では、<br>\n",
        "#@markdown 以下の場合に時間を要する可能性があります。**\n",
        "#@markdown - ModelStatus: 「none」または「origin」\n",
        "#@markdown - NeedYaml: True\n",
        "#@markdown - PipeInstall: True<br>\n",
        "\n",
        "#@markdown *加えて、初回以降でもKindが「1」または「2」では、<br>\n",
        "#@markdown 画像の生成に時間がかかる可能性があります。<br>\n",
        "#@markdown 異常に実行時間が長い場合は以下の事項を確認してください。*\n",
        "#@markdown - Model等のパスが正しいか\n",
        "#@markdown - Modelや画像の容量が大きすぎないか(Model:最大7~8GBあたり)\n",
        "#@markdown - Stepsが多すぎないか(Stepは通常50~80程度)\n",
        "#@markdown - Errorが出ていないか\n",
        "#@markdown - 入力すべき欄で書き忘れがないか\n",
        "#@markdown - GPUを使用しているか\n",
        "#@markdown - 回線が低速でないか\n",
        "#@markdown - 容量(VRAM等)が不足していないか\n",
        "#@markdown - Width,Heightが大きすぎないか(1024*1024ぐらいからかなり時間がかかる)\n",
        "\n",
        "#@markdown また、SDXLを使用すると長くなる傾向にあります。\n",
        "#@markdown ##生成が予想通りにいかない場合<br>\n",
        "#@markdown 以下の点を確認してください。<br>\n",
        "#@markdown - 正しくポジティブプロンプト、ネガティブプロンプトが<br>\n",
        "#@markdown   記述できているか\n",
        "#@markdown - Guidance,Stepsが小さすぎないか\n",
        "#@markdown - **i2iの場合**\n",
        "#@markdown   - 元画像のPathが正しいか\n",
        "#@markdown   - Strengthが極端すぎないか<br>\n",
        "#@markdown     <small>0で変化無し、1で元画像と全く異なる画像が生成されます。</small><br>\n",
        "#@markdown   - Stepsが小さすぎないか\n",
        "#@markdown - Pipelineが正しいか<br>\n",
        "#@markdown   **<small>特に、t2iでインストールしたPipelineを<br>\n",
        "#@markdown   i2iで使用するとt2iとして生成されます。<br>\n",
        "#@markdown   出力の*総Steps数*が*Steps×Strength*と<br>\n",
        "#@markdown   異なる場合はPipelineを<br>\n",
        "#@markdown   再度インストールしてみてください。</small>**\n",
        "model_list_H = ['stablediffusionapi/eleet-model',\n",
        "              'stablediffusionapi/brav6',\n",
        "              'Vsukiyaki/ShiratakiMix',\n",
        "              'stabilityai/stable-diffusion-xl-base-1.0'\n",
        "]\n",
        "\n",
        "model_list_C = [[\"https://civitai.com/api/download/models/28100?type=Model&format=SafeTensor&size=full&fp=fp16\",\"Anime Pastel Dream\"],\n",
        "                [\"https://civitai.com/api/download/models/1410435?type=Model&format=SafeTensor&size=pruned&fp=fp16\",\"WAI-NSFW-illustrious-SDXL v:11.0\"]\n",
        "]\n",
        "\n",
        "mult = 3\n",
        "\n",
        "#drive\n",
        "\"\"\"\n",
        "print(\"Google Driveを使用すると\")\n",
        "print(\"画像が一枚生成されるごとに保存されます。\")\n",
        "drive_use = input(\"Google Driveを使用しますか？ (y/n): \").strip().lower() == \"y\"\n",
        "if drive_use:\n",
        "  from google.colab import drive\n",
        "  import os\n",
        "\n",
        "  # マウントポイント\n",
        "  mount_point = '/content/drive'\n",
        "\n",
        "  # Driveがマウントされているか確認\n",
        "  if not os.path.exists(mount_point):\n",
        "    print(\"Google Driveに接続されていません。接続しますか？ (y/n)\")\n",
        "    connect_drive = input().strip().lower()\n",
        "    if connect_drive == 'y':\n",
        "      drive.mount(mount_point)\n",
        "      print(\"Google Driveに接続しました。\")\n",
        "    else:\n",
        "      print(\"Google Driveへの接続をスキップしました。\")\n",
        "      drive_use = False\n",
        "\n",
        "if drive_use:\n",
        "  print(\"保存する「ディレクトリ」のパスを入力してください。\")\n",
        "  print(\"(例: /content/drive/MyDrive/Colab Notebooks/your_dir)\")\n",
        "  print(\"※指定したディレクトリに追加で階層が生成されます(timestamp)。\")\n",
        "  print(\"保存しない場合は空欄で\")\n",
        "  drive_save = input(\"Path or Empty: \")\n",
        "  if drive_save == \"\":\n",
        "    drive_use = False\n",
        "\n",
        "# ---モード選択---\n",
        "print(\"=== モード選択 ===\")\n",
        "print(\"1: Hugging Faceで画像生成\")\n",
        "print(\"2: CivitAI（モデルDL / safetensors変換）\")\n",
        "print(\"3: トークン数を数える\")\n",
        "print(\"4: 出力フォルダをダウンロード(.zip)\")\n",
        "print(\"5: 出力フォルダを削除\")\n",
        "mode = input(\"番号を入力してください: \").strip()\n",
        "\n",
        "# --- 必要なパラメータを先に全て入力 ---\n",
        "hf_params = {}\n",
        "civitai_params = {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if mode == \"1\":\n",
        "  hf_params[\"need_pipe\"] = input(\"pipelineをインストールしますか？ (y/n): \").strip().lower() == \"y\"\n",
        "  if hf_params[\"need_pipe\"]:\n",
        "    hf_params[\"model_id\"] = input(\"HuggingFaceのモデルIDを入力（例: runwayml/stable-diffusion-v1-5）: \").strip()\n",
        "  hf_params[\"submode\"] = input(\"生成モードを選択（1: text2img, 2: img2img）: \").strip()\n",
        "  hf_params[\"positive_prompt\"] = input(\"プロンプトを入力: \").strip()\n",
        "  hf_params[\"negative_prompt\"] = input(\"ネガティブプロンプトを入力 : \").strip()\n",
        "  hf_params[\"num\"] = int(input(\"生成する画像の枚数 : \"))\n",
        "  hf_params[\"steps\"] = int(input(\"ステップ数（例: 70）: \"))\n",
        "  hf_params[\"guidance\"] = float(input(\"guidance scale（例: 7.5）: \"))\n",
        "  if hf_params[\"submode\"] == \"2\":\n",
        "    hf_params[\"strength\"] = float(input(\"strength (例: 0.75) : \"))\n",
        "    hf_params[\"image_path\"] = input(\"初期画像のパスを入力してください（img2img用）: \")\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "  while True:\n",
        "    print(\"修正する入力がある場合は\")\n",
        "    print(\"num:10\")\n",
        "    print(\"のように入力してください。\")\n",
        "    print(\"ない場合は空欄\")\n",
        "    corr = input(\"入力: \")\n",
        "    if corr == \"\":\n",
        "      break\n",
        "    corr = corr.split(\":\")\n",
        "    if corr[0] in hf_params:\n",
        "      hf_params[corr[0]] = corr[1]\n",
        "    elif corr[0] == \"drive_use\" and not corr[1] == \"y\":\n",
        "      drive_use = False\n",
        "    elif corr[0] == \"drive_use\" or corr[0] == \"drive_save\":\n",
        "      from google.colab import drive\n",
        "      import os\n",
        "      # マウントポイント\n",
        "      mount_point = '/content/drive'\n",
        "      drive_use = True\n",
        "      # Driveがマウントされているか確認\n",
        "      if not os.path.exists(mount_point):\n",
        "        print(\"Google Driveに接続されていません。接続しますか？ (y/n)\")\n",
        "        connect_drive = input().strip().lower()\n",
        "        if connect_drive == 'y':\n",
        "          drive.mount(mount_point)\n",
        "          print(\"Google Driveに接続しました。\")\n",
        "        else:\n",
        "          print(\"Google Driveへの接続をスキップしました。\")\n",
        "          drive_use = False\n",
        "      if corr[1] == \"\":\n",
        "        drive_use = False\n",
        "      if corr[0] == \"drive_use\":\n",
        "        print(\"保存する「ディレクトリ」のパスを入力してください。\")\n",
        "        print(\"(例: /content/drive/MyDrive/Colab Notebooks/your_dir)\")\n",
        "        print(\"※指定したディレクトリに追加で階層が生成されます(timestamp)。\")\n",
        "        print(\"保存しない場合は空欄で\")\n",
        "        drive_save = input(\"Path or Empty: \")\n",
        "        if drive_save == \"\":\n",
        "          drive_use = False\n",
        "        else:\n",
        "          drive_use = True\n",
        "\n",
        "      if corr[0] == \"drive_save\" and drive_use:\n",
        "        drive_save = corr[1]\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "elif mode == \"2\":\n",
        "  print(\"--- CivitAI モデルの状況は？ ---\")\n",
        "  print(\"1: まだ何もしていない（DLも変換もしていない）\")\n",
        "  print(\"2: safetensorsファイルのみアップロード済み（変換が必要）\")\n",
        "  print(\"3: 変換済みでそのまま使える\")\n",
        "  civitai_params[\"status\"] = input(\"番号を入力してください: \").strip()\n",
        "  #civitai_params[\"model_name\"] = input(\"保存先モデル名（例: models）: \").strip()\n",
        "  if civitai_params[\"status\"] == \"1\":\n",
        "    for k in range(len(model_list_C)):\n",
        "      print(f\"{k+1} : {model_list_C[k][1]}\")\n",
        "    civitai_params[\"url\"] = input(\"CivitAIのモデル/LoRA ダウンロードURL: \").strip()\n",
        "    civitai_params[\"sdxl\"] = input(\"モデルはSDXLですか？ (y/n): \").strip().lower() == \"y\"\n",
        "    civitai_params[\"need_yaml\"] = input(\"v1-inference.yamlが必要ですか？ (y/n): \").strip().lower() == \"y\"\n",
        "  elif civitai_params[\"status\"] == \"2\":\n",
        "    print(\"モデルは\")\n",
        "    print(\"「/content/models/downloaded_model.safetensors」\")\n",
        "    print(\"に保存してください。\")\n",
        "    civitai_params[\"sdxl\"] = input(\"モデルはSDXLですか？ (y/n): \").strip().lower() == \"y\"\n",
        "    civitai_params[\"need_yaml\"] = input(\"v1-inference.yamlが必要ですか？ (y/n): \").strip().lower() == \"y\"\n",
        "  else:\n",
        "    civitai_params[\"sdxl\"] = input(\"モデルはSDXLですか？ (y/n): \")\n",
        "  civitai_params[\"need_pipe\"] = input(\"pipelineをインストールしますか？ (y/n): \").strip().lower() == \"y\"\n",
        "  civitai_params[\"submode\"] = input(\"生成モードを選択 (1: text2img, 2: img2img) : \").strip()\n",
        "  civitai_params[\"positive_prompt\"] = input(\"プロンプトを入力してください: \")\n",
        "  civitai_params[\"negative_prompt\"] = input(\"ネガティブプロンプtを入力 : \")\n",
        "  civitai_params[\"num\"] = int(input(\"生成する画像の枚数 : \"))\n",
        "  civitai_params[\"steps\"] = int(input(\"ステップ数（例: 70）: \"))\n",
        "  if civitai_params[\"submode\"] == \"2\":\n",
        "    civitai_params[\"strength\"] = float(input(\"strength (例: 0.75)(img2img用) : \"))\n",
        "    civitai_params[\"image_path\"] = input(\"初期画像のパスを入力してください（例: /content/your_img.png）: \")\n",
        "  civitai_params[\"lora_path\"] = input(\"LoRAを使用する場合はpathを(使わない場合は無入力)\")\n",
        "  if civitai_params[\"lora_path\"] == \"\":\n",
        "    civitai_params[\"lora_path\"] = None\n",
        "\n",
        "\n",
        "elif mode == \"3\":\n",
        "  token_prompt = input(\"プロンプトを入力してください（トークン数確認）: \").strip()\n",
        "\"\"\"\n",
        "\n",
        "if mode == \"4\":\n",
        "  print(\"少々お待ちください。\")\n",
        "\n",
        "elif mode == \"5\":\n",
        "  confirm_delete = input(\"本当にoutputフォルダを削除しますか？ (y/n): \").strip().lower() == \"y\"\n",
        "\n",
        "\n",
        "\n",
        "# --- 必要なinstallはここで実行（全てのinput終了後） ---\n",
        "if mode in [\"1\",\"2\",\"3\",\"4\"] and NeedInstall:\n",
        "  print(\"インストールを開始します...\")\n",
        "  !pip install -r /content/drive/MyDrive/Colab\\ Notebooks/share_dir/AI_IMG/requirements.txt\n",
        "\n",
        "# Load Hugging Face token from secrets\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "except:\n",
        "    HF_TOKEN = None\n",
        "    print(\"Warning: Could not load Hugging Face token from Colab secrets.\")\n",
        "\n",
        "\n",
        "def tokenCounter(token_k):\n",
        "  from transformers import CLIPTokenizer\n",
        "  tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\", token=HF_TOKEN)\n",
        "  tokens = tokenizer(token_k)[\"input_ids\"]\n",
        "  return len(tokens)\n",
        "\n",
        "# --- 各モード実行 ---\n",
        "if mode == \"1\":\n",
        "  pos_num = tokenCounter(hf_params[\"positive_prompt\"])\n",
        "  neg_num = tokenCounter(hf_params[\"negative_prompt\"])\n",
        "  print(\"Token数\")\n",
        "  print(\" - Positive : \"+str(pos_num))\n",
        "  print(\" - Negative : \"+str(neg_num))\n",
        "  mult = 1+max(pos_num, neg_num) // 77\n",
        "  print(\" - multiple : \"+str(mult))\n",
        "\n",
        "  from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
        "  from PIL import Image, ImageOps\n",
        "  import torch\n",
        "  import os\n",
        "  from datetime import datetime, timedelta\n",
        "  jst = datetime.utcnow() + timedelta(hours=9)\n",
        "  timeDir = {\n",
        "      \"y\":jst.strftime(\"%Y\"),\n",
        "      \"m\":jst.strftime(\"%m\"),\n",
        "      \"d\":jst.strftime(\"%d\"),\n",
        "      \"t\":jst.strftime(\"%H-%M-%S\")\n",
        "      }\n",
        "  timestamp = jst.strftime(\"%Y%m%d_%H%M%S\")\n",
        "  torch_dtype = torch.float16\n",
        "\n",
        "  if 'model_id' not in hf_params:\n",
        "    hf_params[\"model_id\"] = \"unknown\"\n",
        "  if hf_params[\"need_pipe\"]:\n",
        "    if hf_params[\"submode\"] == \"1\":\n",
        "      pipe = StableDiffusionPipeline.from_pretrained(\n",
        "        hf_params[\"model_id\"],\n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None,  # Safe checkを無効に\n",
        "        custom_pipeline=\"lpw_stable_diffusion\"\n",
        "      )\n",
        "      pipe = pipe.to(\"cuda\")  # GPUが必要です\n",
        "    else:\n",
        "      pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "        hf_params[\"model_id\"],\n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None,\n",
        "        custom_pipeline=\"lpw_stable_diffusion\"\n",
        "      )\n",
        "      pipe = pipe.to(\"cuda\")\n",
        "  if hf_params[\"submode\"] != \"1\":\n",
        "    init_image = Image.open(hf_params[\"image_path\"]).convert(\"RGB\")\n",
        "    if not OriginSize:\n",
        "      init_image = ImageOps.fit(init_image, (Width, Height), method=Image.Resampling.LANCZOS)\n",
        "  for k in range(hf_params[\"num\"]):\n",
        "    if hf_params[\"submode\"] == \"1\":\n",
        "\n",
        "      image = pipe(hf_params[\"positive_prompt\"],\n",
        "                   negative_prompt=hf_params[\"negative_prompt\"],\n",
        "                   num_inference_steps=hf_params[\"steps\"],\n",
        "                   width=Width,\n",
        "                   height=Height,\n",
        "                   guidance_scale=hf_params[\"guidance\"],\n",
        "                   added_cond_kwargs={},\n",
        "                   max_embeddings_multiples=mult\n",
        "                ).images[0]\n",
        "    else:\n",
        "      #init_image = Image.open(hf_params[\"image_path\"]).convert(\"RGB\").resize((512, 512))\n",
        "      image = pipe(prompt=hf_params[\"positive_prompt\"],\n",
        "                   negative_prompt=hf_params[\"negative_prompt\"],\n",
        "                   num_inference_steps=hf_params[\"steps\"],\n",
        "                   image=init_image,\n",
        "                   strength=hf_params[\"strength\"],\n",
        "                   width=Width,\n",
        "                   height=Height,\n",
        "                   guidance_scale=hf_params[\"guidance\"],\n",
        "                   max_embeddings_multiples=mult\n",
        "                ).images[0]\n",
        "    if drive_use:\n",
        "      save_dir = os.path.join(\n",
        "          drive_save,\n",
        "          timeDir[\"y\"]+\"-\"+timeDir[\"m\"],\n",
        "          timeDir[\"d\"],\n",
        "          timeDir[\"t\"]\n",
        "      )\n",
        "\n",
        "      os.makedirs(save_dir, exist_ok=True)\n",
        "      image.save(save_dir+\"/\"+str(k+1)+\".png\")\n",
        "\n",
        "      # プロンプトとネガティブプロンプトを保存（1回目のみ）\n",
        "      if k == 0:\n",
        "        if hf_params[\"submode\"] != \"1\":\n",
        "          init_image.save(save_dir+\"/origin.png\")\n",
        "        with open(os.path.join(save_dir, \"info.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "          if hf_params[\"submode\"] == \"1\":\n",
        "            f.write(\"t2i\\n\\n\")\n",
        "            f.write(\"Width,Height:\\n\"+str(Width)+','+str(Height)+'\\n\\n')\n",
        "          else:\n",
        "            f.write(\"i2i\\n\\n\")\n",
        "          f.write(\"Model:\\nHugging Face / \"+hf_params[\"model_id\"]+\"\\n\\n\")\n",
        "          f.write(\"Num_Inference_Steps:\\n\"+str(hf_params[\"steps\"])+\"\\n\\n\")\n",
        "          if hf_params[\"submode\"] != \"1\":\n",
        "            f.write(\"Strength:\\n\"+str(hf_params[\"strength\"])+\"\\n\\n\")\n",
        "          f.write(\"Positive Prompt:\"+str(pos_num)+\"\\n\" + hf_params[\"positive_prompt\"] + \"\\n\\n\")\n",
        "          f.write(\"Negative Prompt:\"+str(neg_num)+\"\\n\" + hf_params[\"negative_prompt\"])\n",
        "\n",
        "    else:\n",
        "      os.makedirs(\"output/\"+timestamp+\"/\"+hf_params[\"positive_prompt\"][0:10], exist_ok=True)\n",
        "      filename = f\"output/\"+timestamp+\"/\"+hf_params[\"positive_prompt\"][0:10]+\"/\"+str(k+1)+\".png\"\n",
        "      image.save(filename)\n",
        "  print(\"画像を保存しました\")\n",
        "\n",
        "elif mode == \"2\":\n",
        "  pos_num = tokenCounter(civitai_params[\"positive_prompt\"])\n",
        "  neg_num = tokenCounter(civitai_params[\"negative_prompt\"])\n",
        "  print(\"Token数\")\n",
        "  print(\" - Positive : \"+str(pos_num))\n",
        "  print(\" - Negative : \"+str(neg_num))\n",
        "  mult = 1+max(pos_num, neg_num) // 77 # Re-add max_embeddings_multiples calculation\n",
        "  print(\" - multiple : \"+str(mult)) # Re-add printing multiple\n",
        "  import os\n",
        "  import torch\n",
        "  import re\n",
        "  import requests\n",
        "  from datetime import datetime, timedelta\n",
        "  jst = datetime.utcnow() + timedelta(hours=9)\n",
        "  timeDir = {\n",
        "      \"y\":jst.strftime(\"%Y\"),\n",
        "      \"m\":jst.strftime(\"%m\"),\n",
        "      \"d\":jst.strftime(\"%d\"),\n",
        "      \"t\":jst.strftime(\"%H-%M-%S\")\n",
        "      }\n",
        "  timestamp = jst.strftime(\"%Y%m%d_%H%M%S\")\n",
        "  if civitai_params[\"submode\"] == \"2\":\n",
        "    from PIL import Image, ImageOps\n",
        "    from IPython.display import display\n",
        "\n",
        "\n",
        "  base_dir = \"/content/models\"\n",
        "  os.makedirs(base_dir, exist_ok=True)\n",
        "  download_path = \"/content/models/downloaded_model.safetensors\"\n",
        "\n",
        "  #※Driveのinfo.txtに書くための変数!!\n",
        "  # modelName = \"unknown\"\n",
        "  # if \"Model\" in locals():\n",
        "  #   regex = r'([0-9]+)'\n",
        "  #   regex2 = r'#(\\d+)'\n",
        "  #   if bool(re.match(regex, Model)):\n",
        "  #     modelName = model_list_C[int(Model)-1][1]\n",
        "  #   else:\n",
        "  #     match = re.fullmatch(regex2, Model)\n",
        "  #     if match:\n",
        "  #       modelName = \"model_id:\" + match.group(1)\n",
        "  #     else:\n",
        "  #       modelName = Model\n",
        "\n",
        "\n",
        "  if civitai_params[\"status\"] == \"1\":\n",
        "    regex = r'([0-9]+)'\n",
        "    regex2 = r'#(\\d+)'\n",
        "    if bool(re.match(regex, civitai_params['url'])):\n",
        "      civitai_params['url'] = model_list_C[int(civitai_params['url'])-1][0]\n",
        "    else:\n",
        "      match = re.fullmatch(regex2, civitai_params['url'])\n",
        "      if match:\n",
        "        civitai_params['url'] = 'https://civitai.com/api/download/models/'+match.group(1)\n",
        "\n",
        "    model_url = civitai_params[\"url\"]\n",
        "\n",
        "    print(model_url)\n",
        "\n",
        "    print(f\"Downloading Checkpoint model to {download_path}...\")\n",
        "    !wget -O {download_path} \"{model_url}\"\n",
        "    print(f\"Download of safetensorFile complete!\")\n",
        "\n",
        "\n",
        "  lora_path = civitai_params[\"lora_path\"] # LoRAはダウンロードしないとNone\n",
        "\n",
        "  # Download LoRA if URL is provided\n",
        "  if lora_path and lora_path.startswith(\"http\"):\n",
        "      lora_filename = lora_path.split(\"/\")[-1].split(\"?\")[0] # Extract filename from URL\n",
        "      lora_download_path = os.path.join(base_dir, lora_filename)\n",
        "      print(f\"Downloading LoRA model to {lora_download_path}...\")\n",
        "      try:\n",
        "          response = requests.get(lora_path, stream=True)\n",
        "          response.raise_for_status() # Raise an exception for bad status codes\n",
        "          with open(lora_download_path, 'wb') as f:\n",
        "              for chunk in response.iter_content(chunk_size=8192):\n",
        "                  f.write(chunk)\n",
        "          print(f\"Download of LoRA file complete!\")\n",
        "          lora_path = lora_download_path # Update lora_path to the local file path\n",
        "      except requests.exceptions.RequestException as e:\n",
        "          print(f\"Error downloading LoRA file: {e}\")\n",
        "          lora_path = None # Set lora_path to None if download fails\n",
        "\n",
        "\n",
        "  if civitai_params[\"status\"] == \"1\" or civitai_params[\"status\"] == \"2\":\n",
        "    # Determine the checkpoint path for conversion\n",
        "    conversion_checkpoint_path = civitai_params.get(\"model_insert_path\")\n",
        "    if not conversion_checkpoint_path or not os.path.exists(conversion_checkpoint_path):\n",
        "        # If no insert path or path doesn't exist, use the downloaded path\n",
        "        conversion_checkpoint_path = download_path\n",
        "\n",
        "    if civitai_params[\"need_yaml\"]:\n",
        "      !wget -O /content/models/v1-inference.yaml \\\n",
        "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "      #!wget -q https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-inference.yaml\n",
        "    if not civitai_params[\"sdxl\"]:\n",
        "      !mkdir /content/converted\n",
        "      !wget -O convert_original_stable_diffusion_to_diffusers.py \\\n",
        "      https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "      os.makedirs(base_dir, exist_ok=True)\n",
        "      !python convert_original_stable_diffusion_to_diffusers.py \\\n",
        "        --checkpoint_path \"{conversion_checkpoint_path}\" \\\n",
        "        --original_config_file ./models/v1-inference.yaml \\\n",
        "        --dump_path ./converted/diffusers_model \\\n",
        "        --from_safetensors\n",
        "\n",
        "  # Determine the model path to load for pipeline\n",
        "  model_load_path = civitai_params.get(\"model_insert_path\")\n",
        "  if not model_load_path or not os.path.exists(model_load_path): # Add check for existence\n",
        "      if civitai_params[\"status\"] == \"1\" or civitai_params[\"status\"] == \"2\":\n",
        "          # If status is 1 or 2, and no insert path or path doesn't exist, use the downloaded/converted path\n",
        "          model_load_path = \"/content/converted/diffusers_model\" if not civitai_params[\"sdxl\"] else download_path\n",
        "      elif civitai_params[\"status\"] == \"3\":\n",
        "          # If status is 3, use the default path for complete models\n",
        "          model_load_path = \"/content/converted/diffusers_model\" if not civitai_params[\"sdxl\"] else download_path # Assuming default path for complete models is the same\n",
        "\n",
        "  #pipe = None\n",
        "  if civitai_params[\"need_pipe\"]:\n",
        "    if civitai_params[\"sdxl\"]:\n",
        "      if os.path.isfile(model_load_path): # Check if it's a file\n",
        "          from diffusers import StableDiffusionXLPipeline\n",
        "          pipe_civitai = StableDiffusionXLPipeline.from_single_file(\n",
        "              model_load_path, # Use model_load_path\n",
        "              torch_dtype=torch.float16, # fp16モデルなので必須\n",
        "              use_safetensors=True,      # safetensors形式であることを明示\n",
        "              safety_checker=None,\n",
        "              custom_pipeline=\"lpw_stable_diffusion\" # Ensure custom pipeline is used\n",
        "          ).to(\"cuda\")\n",
        "      else: # Assume it's a directory\n",
        "           from diffusers import StableDiffusionXLPipeline\n",
        "           pipe_civitai = StableDiffusionXLPipeline.from_pretrained(\n",
        "              model_load_path, # Use model_load_path\n",
        "              torch_dtype=torch.float16, # fp16モデルなので必須\n",
        "              safety_checker=None,\n",
        "              custom_pipeline=\"lpw_stable_diffusion\" # Ensure custom pipeline is used\n",
        "          ).to(\"cuda\")\n",
        "    else: # Not SDXL\n",
        "      if os.path.isfile(model_load_path): # Check if it's a file\n",
        "          from diffusers import StableDiffusionPipeline\n",
        "          pipe_civitai = StableDiffusionPipeline.from_single_file(\n",
        "              model_load_path, # Use model_load_path\n",
        "              torch_dtype=torch.float16,\n",
        "              use_safetensors=True, # Assuming single files are safetensors\n",
        "              safety_checker=None,\n",
        "              custom_pipeline=\"lpw_stable_diffusion\" # Ensure custom pipeline is used\n",
        "          ).to(\"cuda\")\n",
        "      else: # Assume it's a directory\n",
        "          from diffusers import StableDiffusionPipeline\n",
        "          #pipe = StableDiffusionPipeline.from_pretrained(base_dir, torch_dtype=torch.float16).to(\"cuda\")\n",
        "          pipe_civitai = StableDiffusionPipeline.from_pretrained(\n",
        "              model_load_path, # Use model_load_path\n",
        "              torch_dtype=torch.float16,\n",
        "              use_safetensors=False, # Assuming directories are not safetensors\n",
        "              safety_checker=None,\n",
        "              custom_pipeline=\"lpw_stable_diffusion\" # Ensure custom pipeline is used\n",
        "            ).to(\"cuda\")\n",
        "    # パイプラインを作成した直後に以下を追加します\n",
        "    if lora_path and os.path.exists(lora_path): # Add a check if lora_path exists after download\n",
        "      pipe_civitai.load_lora_weights(lora_path, use_safetensors=True)\n",
        "\n",
        "  modelName_civitai = model_load_path if model_load_path and os.path.exists(model_load_path) else (pipe_civitai.pretrained_model_name_or_path if hasattr(pipe_civitai, 'pretrained_model_name_or_path') else \"unknown\")\n",
        "\n",
        "\n",
        "  if civitai_params[\"submode\"] == \"1\":\n",
        "  #pipe.enable_xformers_memory_efficient_attention()\n",
        "    for k in range(civitai_params[\"num\"]):\n",
        "      image = pipe_civitai(prompt=civitai_params[\"positive_prompt\"],\n",
        "          negative_prompt=civitai_params[\"negative_prompt\"],\n",
        "          num_inference_steps=civitai_params[\"steps\"],\n",
        "          width=Width,\n",
        "          height=Height,\n",
        "          guidance_scale=civitai_params[\"guidance\"],\n",
        "          max_embeddings_multiples=mult # Add max_embeddings_multiples back\n",
        "      ).images[0]\n",
        "      if drive_use:\n",
        "        save_dir = os.path.join(\n",
        "            drive_save,\n",
        "            timeDir[\"y\"]+\"-\"+timeDir[\"m\"],\n",
        "            timeDir[\"d\"],\n",
        "            timeDir[\"t\"]\n",
        "          )\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        image.save(save_dir+\"/\"+str(k+1)+\".png\")\n",
        "\n",
        "        # プロンプトとネガティブプロンプトを保存（1回目のみ）\n",
        "        if k == 0:\n",
        "          with open(os.path.join(save_dir, \"info.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"t2i\\n\\n\")\n",
        "            f.write(\"Width,Height:\\n\"+str(Width)+\",\"+str(Height)+\"\\n\\n\")\n",
        "            if civitai_params[\"sdxl\"]:\n",
        "              f.write(\"Model:\\nCivitAI(SDXL) / \"+modelName_civitai+\"\\n\\n\")\n",
        "            else:\n",
        "              f.write(\"Model:\\nCivitAI / \"+modelName_civitai+\"\\n\\n\")\n",
        "            f.write(\"Num_Inference_Steps:\\n\"+str(civitai_params[\"steps\"])+\"\\n\\n\")\n",
        "            if civitai_params[\"submode\"] != \"1\":\n",
        "              f.write(\"Strength:\\n\"+str(civitai_params[\"strength\"])+\"\\n\\n\")\n",
        "            f.write(\"Positive Prompt:\"+str(pos_num)+\"\\n\" + civitai_params[\"positive_prompt\"] + \"\\n\\n\")\n",
        "            f.write(\"Negative Prompt:\"+str(neg_num)+\"\\n\" + civitai_params[\"negative_prompt\"])\n",
        "\n",
        "      else:\n",
        "        os.makedirs(\"output/t2i/\"+timestamp+\"/\"+civitai_params[\"positive_prompt\"][0:10], exist_ok=True)\n",
        "        image.save(\"output/t2i/\"+timestamp+\"/\"+civitai_params[\"positive_prompt\"][0:10]+\"/\"+str(k+1)+\".png\")\n",
        "    print(\"画像を保存しました: output/t2i/\"+timestamp+\"/\"+civitai_params[\"positive_prompt\"][0:10])\n",
        "  else:\n",
        "    init_image = Image.open(civitai_params[\"image_path\"]).convert(\"RGB\")\n",
        "    img_width, img_height = init_image.size\n",
        "    if not OriginSize:\n",
        "      init_image = ImageOps.fit(init_image, (Width, Height), method=Image.Resampling.LANCZOS)\n",
        "      img_width = Width\n",
        "      img_height = Height\n",
        "    #display(init_image)\n",
        "    for k in range(civitai_params[\"num\"]):\n",
        "      image = pipe_civitai(prompt=civitai_params[\"positive_prompt\"],\n",
        "          negative_prompt=civitai_params[\"negative_prompt\"],\n",
        "          image=init_image,\n",
        "          num_inference_steps=civitai_params[\"steps\"],\n",
        "          strength=civitai_params[\"strength\"],\n",
        "          width=img_width,\n",
        "          height=img_height,\n",
        "          guidance_scale=civitai_params[\"guidance\"],\n",
        "          max_embeddings_multiples=mult # Add max_embeddings_multiples back\n",
        "      ).images[0]\n",
        "      if drive_use:\n",
        "        save_dir = os.path.join(\n",
        "            drive_save,\n",
        "            timeDir[\"y\"]+\"-\"+timeDir[\"m\"],\n",
        "            timeDir[\"d\"],\n",
        "            timeDir[\"t\"]\n",
        "          )\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        image.save(save_dir+\"/\"+str(k+1)+\".png\")\n",
        "\n",
        "        # プロンプトとネガティブプロンプトを保存（1回目のみ）\n",
        "        if k == 0:\n",
        "          init_image.save(save_dir+\"/origin.png\")\n",
        "          with open(os.path.join(save_dir, \"info.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(\"i2i\\n\\n\")\n",
        "            if civitai_params[\"sdxl\"]:\n",
        "              f.write(\"Model:\\nCivitAI(SDXL) / \"+modelName_civitai+\"\\n\\n\")\n",
        "            else:\n",
        "              f.write(\"Model:\\nCivitAI / \"+modelName_civitai+\"\\n\\n\")\n",
        "            f.write(\"Num_Inference_Steps:\\n\"+str(civitai_params[\"steps\"])+\"\\n\\n\")\n",
        "            f.write(\"Strength:\\n\"+str(civitai_params[\"strength\"])+\"\\n\\n\")\n",
        "            f.write(\"Size:\\nw...\"+str(img_width)+\",h...\"+str(img_height)+\"\\n\\n\")\n",
        "            f.write(\"Positive Prompt:\"+str(pos_num)+\"\\n\" + civitai_params[\"positive_prompt\"] + \"\\n\\n\")\n",
        "            f.write(\"Negative Prompt:\"+str(neg_num)+\"\\n\" + civitai_params[\"negative_prompt\"])\n",
        "      else:\n",
        "        os.makedirs(\"output/i2i/\"+timestamp+\"/\"+civitai_params[\"positive_prompt\"][0:10], exist_ok=True)\n",
        "        image.save(\"output/i2i/\"+timestamp+\"/\"+civitai_params[\"positive_prompt\"][0:10]+\"/\"+str(k+1)+\".png\")\n",
        "    print(\"画像を保存しました: output/i2i/\"+timestamp+\"/\"+civitai_params[\"positive_prompt\"][0:10])\n",
        "\n",
        "  \"\"\"\n",
        "  resize_params = {\n",
        "    \"status\": (\n",
        "      \"1\" if Model_Status == \"none\"\n",
        "      else \"2\" if Model_Status == \"origin\"\n",
        "      else \"3\"\n",
        "    ),\n",
        "    \"sdxl\": Sdxl,\n",
        "    \"need_yaml\": NeedYaml,\n",
        "    #\"need_yaml\": (Model_Status in [\"none\", \"origin\"] and Sdxl),\n",
        "    \"need_pipe\": PipeInstall,\n",
        "    \"submode\": \"2\" if SubMode == \"i2i\" else \"1\",\n",
        "    \"positive_prompt\": Positive_Prompt,\n",
        "    \"negative_prompt\": Negative_Prompt,\n",
        "    \"num\": Num,\n",
        "    \"steps\": Steps,\n",
        "    \"url\": Model,\n",
        "    \"strength\" = Strength,\n",
        "    \"image_path = ImagePath,\n",
        "  }\n",
        "  \"\"\"\n",
        "elif mode == \"3\":\n",
        "  #マスク作成\n",
        "\n",
        "\n",
        "  #既にインストールされてるから要らない\n",
        "  #!pip install pillow\n",
        "\n",
        "  from PIL import Image, ImageOps\n",
        "  from diffusers import StableDiffusionControlNetInpaintPipeline, ControlNetModel, DDIMScheduler\n",
        "  from diffusers.utils import load_image\n",
        "  import numpy as np\n",
        "  import torch\n",
        "  import os\n",
        "  from datetime import datetime, timedelta\n",
        "  jst = datetime.utcnow() + timedelta(hours=9)\n",
        "  timeDir = {\n",
        "      \"y\":jst.strftime(\"%Y\"),\n",
        "      \"m\":jst.strftime(\"%m\"),\n",
        "      \"d\":jst.strftime(\"%d\"),\n",
        "      \"t\":jst.strftime(\"%H-%M-%S\")\n",
        "      }\n",
        "  timestamp = jst.strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "  pos_num = \"?\"\n",
        "  neg_num = \"?\"\n",
        "\n",
        "  modelName_resize_base = \"runwayml/stable-diffusion-v1-5\"\n",
        "\n",
        "  # ----------- 変数定義 -----------\n",
        "  #path = resize_params[\n",
        "  w, h = Width, Height  # 出力サイズ\n",
        "  # --------------------------------\n",
        "\n",
        "  # 元画像読み込み\n",
        "  img = Image.open(resize_params[\"image_path\"]).convert(\"RGB\")\n",
        "  w0, h0 = img.size\n",
        "  rw, rh = w / w0, h / h0\n",
        "\n",
        "  # サイズに応じてリサイズ＆パディング\n",
        "  if resize_params[\"mask_path\"] == \"\":\n",
        "    if rw < rh:\n",
        "      new_w = w\n",
        "      new_h = int(h0 * rw)\n",
        "      resized = img.resize((new_w, new_h), resample=Image.Resampling.LANCZOS)\n",
        "      pad_top = (h - new_h) // 2\n",
        "      pad_bottom = h - new_h - pad_top\n",
        "      pad = (0, pad_top, 0, pad_bottom)\n",
        "    else:\n",
        "      new_h = h\n",
        "      new_w = int(w0 * rh)\n",
        "      resized = img.resize((new_w, new_h), resample=Image.Resampling.LANCZOS)\n",
        "      pad_left = (w - new_w) // 2\n",
        "      pad_right = w - new_w - pad_left\n",
        "      pad = (pad_left, 0, pad_right, 0)\n",
        "\n",
        "    # 余白追加済み画像の生成\n",
        "    init_image = ImageOps.expand(resized, border=pad, fill=(255, 255, 255))\n",
        "\n",
        "\n",
        "    # マスク画像（余白のみ白、他は黒）\n",
        "    mask_image = Image.new(\"L\", (w, h), color=255)\n",
        "    mask_image.paste(0, box=(pad[0], pad[1], w - pad[2], h - pad[3]))\n",
        "  else:\n",
        "    init_image = img\n",
        "    mask_image = load_image(\n",
        "      resize_params[\"mask_path\"]\n",
        "    )\n",
        "    mask_image = Image.open(resize_params[\"mask_path\"]).convert(\"L\")\n",
        "    mask_image = mask_image.resize((w0,h0))\n",
        "  #mask_image.paste(0, box=(pad[0], pad[1], w - pad[2], h - pad[3]))\n",
        "  # 保存\n",
        "\n",
        "  #os.makedirs(\"/content/gen\",exist_ok=True)\n",
        "  #init_image.save(\"gen/padded_image.png\")\n",
        "  #mask_image.save(\"gen/mask_image.png\")\n",
        "\n",
        "  #install_tf = False\n",
        "\n",
        "\n",
        "  #if install_tf:\n",
        "  #  !pip install transformers accelerate\n",
        "\n",
        "\n",
        "\n",
        "  \"\"\"init_image = load_image(\n",
        "    #\"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main/stable_diffusion_inpaint/boy.png\"\n",
        "    \"/content/gen/padded_image.png\"\n",
        "  )\"\"\"\n",
        "  #init_image = init_image.resize((512, 512))\n",
        "\n",
        "  if resize_params[\"install_tf\"]:\n",
        "    generator = torch.Generator(device=\"cpu\").manual_seed(1)\n",
        "\n",
        "\n",
        "  #mask_image = mask_image.resize((512, 512))\n",
        "\n",
        "\n",
        "  def make_inpaint_condition(image, image_mask):\n",
        "    image = np.array(image.convert(\"RGB\")).astype(np.float32) / 255.0\n",
        "    image_mask = np.array(image_mask.convert(\"L\")).astype(np.float32) / 255.0\n",
        "\n",
        "    assert image.shape[0:1] == image_mask.shape[0:1], \"image and image_mask must have the same image size\"\n",
        "    image[image_mask > 0.5] = -1.0  # set as masked pixel\n",
        "    image = np.expand_dims(image, 0).transpose(0, 3, 1, 2)\n",
        "    image = torch.from_numpy(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "  control_image = make_inpaint_condition(init_image, mask_image)\n",
        "\n",
        "  controlnet = ControlNetModel.from_pretrained(\n",
        "    \"lllyasviel/control_v11p_sd15_inpaint\", torch_dtype=torch.float16\n",
        "  )\n",
        "\n",
        "  # Determine the model path to load for resize\n",
        "  model_load_path_resize = resize_params.get(\"model_insert_path\")\n",
        "  if not model_load_path_resize or not os.path.exists(model_load_path_resize): # Add check for existence\n",
        "      # If no insert path or path doesn't exist, use the default base model\n",
        "      model_load_path_resize = modelName_resize_base\n",
        "\n",
        "\n",
        "  if resize_params[\"install_tf\"]:\n",
        "    if os.path.isfile(model_load_path_resize): # Check if it's a file\n",
        "        pipe_resize = StableDiffusionControlNetInpaintPipeline.from_single_file(\n",
        "            model_load_path_resize, controlnet=controlnet, torch_dtype=torch.float16, # Use model_load_path_resize\n",
        "            safety_checker=None,\n",
        "            use_safetensors=True, # Assuming single files are safetensors\n",
        "            custom_pipeline=\"lpw_stable_diffusion\" # Ensure custom pipeline is used\n",
        "        )\n",
        "    else: # Assume it's a directory or huggingface model id\n",
        "        pipe_resize = StableDiffusionControlNetInpaintPipeline.from_pretrained(\n",
        "            model_load_path_resize, controlnet=controlnet, torch_dtype=torch.float16, # Use model_load_path_resize\n",
        "            safety_checker=None,\n",
        "            custom_pipeline=\"lpw_stable_diffusion\" # Ensure custom pipeline is used\n",
        "        )\n",
        "\n",
        "\n",
        "    pipe_resize.scheduler = DDIMScheduler.from_config(pipe_resize.scheduler.config)\n",
        "    pipe_resize.enable_model_cpu_offload()\n",
        "\n",
        "  modelName_resize = model_load_path_resize if model_load_path_resize and os.path.exists(model_load_path_resize) else (pipe_resize.pretrained_model_name_or_path if hasattr(pipe_resize, 'pretrained_model_name_or_path') else \"unknown\")\n",
        "\n",
        "  #positive_prompt = \"anime, colorful eyes, 1girl, floating, golden fox ears, golden long hair, elegant face, gentle smile, modest dress, natural fingers, starlit sky, magical glow, colorful light particles, soft rainbow haze, aurora sky, bluish shadows, faint magenta glow, delicate warm light\"\n",
        "  #negative_prompt = \"bad hands, extra fingers, fused fingers, deformed hands, missing fingers, worst quality, low quality\"\n",
        "  #positive_prompt = resize_params[\"positive_prompt\"]\n",
        "  #negative_prompt = resize_params[\"negative_prompt\"]\n",
        "  #num = 10\n",
        "  #steps = 100\n",
        "\n",
        "  #os.makedirs(\"/content/result/\"+prompt[0:10], exist_ok=True)\n",
        "\n",
        "  # generate image\n",
        "  for k in range(resize_params[\"num\"]):\n",
        "    image = pipe_resize(\n",
        "      resize_params[\"positive_prompt\"],\n",
        "      negative_prompt=resize_params[\"negative_prompt\"],\n",
        "      num_inference_steps=resize_params[\"steps\"],\n",
        "      generator=generator,\n",
        "      eta=1.0,\n",
        "      image=init_image,\n",
        "      mask_image=mask_image,\n",
        "      control_image=control_image,\n",
        "      max_embeddings_multiples=mult # Add max_embeddings_multiples back\n",
        "\n",
        "    ).images[0]\n",
        "\n",
        "    #init_image = Image.open(civitai_params[\"image_path\"]).convert(\"RGB\")\n",
        "    #init_image = ImageOps.fit(init_image, (1024, 1024), method=Image.Resampling.LANCZOS)\n",
        "    #display(init_image)\n",
        "    #for k in range(civitai_params[\"num\"]):\n",
        "    \"\"\"image = pipe_civitai(prompt=civitai_params[\"positive_prompt\"],\n",
        "          negative_prompt=civitai_params[\"negative_prompt\"],\n",
        "          image=init_image,\n",
        "          num_inference_steps=civitai_params[\"steps\"],\n",
        "          strength=civitai_params[\"strength\"],\n",
        "          width=Width,\n",
        "          height=Height,\n",
        "          guidance_scale=civitai_params[\"guidance\"],\n",
        "    ).images[0]\"\"\"\n",
        "    if drive_use:\n",
        "      save_dir = os.path.join(\n",
        "          drive_save,\n",
        "          timeDir[\"y\"]+\"-\"+timeDir[\"m\"],\n",
        "          timeDir[\"d\"],\n",
        "          timeDir[\"t\"]\n",
        "        )\n",
        "      os.makedirs(save_dir, exist_ok=True)\n",
        "      image.save(save_dir+\"/\"+str(k+1)+\".png\")\n",
        "\n",
        "      # プロンプトとネガティブプロンプトを保存（1回目のみ）\n",
        "      if k == 0:\n",
        "        img.save(save_dir+\"/origin.png\")\n",
        "        mask_image.save(save_dir+\"/mask.png\")\n",
        "        with open(os.path.join(save_dir, \"info.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "          f.write(\"resize\\n\\n\")\n",
        "          #if civitai_params[\"sdxl\"]:\n",
        "          #  f.write(\"Model:\\nCivitAI(SDXL) / \"+modelName+\"\\n\\n\")\n",
        "          #else:\n",
        "          #  f.write(\"Model:\\nCivitAI / \"+modelName+\"\\n\\n\")\n",
        "          if resize_params[\"mask_path\"] == \"\":\n",
        "            f.write(\"Width, Height:\\nw...\"+str(w)+\", h...\"+str(h)+\"\\n\\n\")\n",
        "          else:\n",
        "            f.write(\"Width, Height:\\nw...\"+str(w0)+\", h...\"+str(h0)+\"\\n\\n\")\n",
        "          f.write(\"Model:\\n\"+modelName_resize+\"\\n\\n\")\n",
        "          f.write(\"Num_Inference_Steps:\\n\"+str(resize_params[\"steps\"])+\"\\n\\n\")\n",
        "          #f.write(\"Strength:\\n\"+str(civitai_params[\"strength\"])+\"\\n\\n\")\n",
        "          f.write(\"Positive Prompt:\\n\" + resize_params[\"positive_prompt\"] + \"\\n\\n\")\n",
        "          f.write(\"Negative Prompt:\\n\" + resize_params[\"negative_prompt\"])\n",
        "    else:\n",
        "      os.makedirs(\"output/i2i/\"+timestamp+\"/\"+resize_params[\"positive_prompt\"][0:10], exist_ok=True)\n",
        "      image.save(\"output/i2i/\"+timestamp+\"/\"+resize_params[\"positive_prompt\"][0:10]+\"/\"+str(k+1)+\".png\")\n",
        "  print(\"画像を保存しました: output/i2i/\"+timestamp+\"/\"+resize_params[\"positive_prompt\"][0:10])\n",
        "\n",
        "  #pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))\n",
        "  #image.save(\"result/\"+prompt[0:10]+\"/\"+str(k)+\".png\")\n",
        "\n",
        "elif mode == \"4\":\n",
        "  print(\"Token数 : \"+str(tokenCounter(token_prompt)))\n",
        "\n",
        "elif mode == \"5\":\n",
        "  import shutil\n",
        "  from google.colab import files\n",
        "\n",
        "  # 圧縮したいディレクトリのパス\n",
        "  folder_path = DirPath\n",
        "  zip_filename = folder_path + '.zip'\n",
        "\n",
        "  # ディレクトリを zip 形式で圧縮\n",
        "  shutil.make_archive(folder_path, 'zip', folder_path)\n",
        "\n",
        "  # Colab にダウンロードリンクを表示\n",
        "  files.download(zip_filename)\n",
        "\n",
        "\n",
        "elif mode == \"6\":\n",
        "  import shutil\n",
        "  if confirm_delete:\n",
        "    if os.path.exists(DirPath) and os.path.isdir(DirPath):\n",
        "      shutil.rmtree(DirPath)\n",
        "      print(f\"{DirPath} を削除しました。\")\n",
        "    else:\n",
        "      print(f\"{DirPath} は存在しないか、ディレクトリではありません。\")\n",
        "  else:\n",
        "    print(\"キャンセルされました\")\n",
        "\n",
        "elif mode == \"7\":\n",
        "  default_params = {\n",
        "    \"Drive_path\": \"\",\n",
        "    \"Kind\": \"Hugging Face\",\n",
        "    \"SubMode\": \"t2i\",\n",
        "    \"Prompt\": \"\",\n",
        "    \"Negative_Prompt\": \"\",\n",
        "    \"Num\": 10,\n",
        "    \"Steps\": 50,\n",
        "    \"ImagePath\": \"\",\n",
        "    \"Strength\": 0.75,\n",
        "    \"Guidance\": 7.5,\n",
        "    \"Model_Status\": \"none\",\n",
        "    \"Model\": \"2\",\n",
        "    \"Sdxl\": True,\n",
        "    \"PipeInstall\": True,\n",
        "    \"LoraPath\": \"\"\n",
        "  }\n",
        "\n",
        "  for k in default_params.keys():\n",
        "    if type(default_params[k]) == int or type(default_params[k]) == float:\n",
        "      print(k+\" : \"+str(default_params[k]))\n",
        "    elif type(default_params[k]) == bool:\n",
        "      print(k+\" : \"+str(default_params[k]))\n",
        "    else:\n",
        "      print(k+' : \"'+default_params[k]+'\"')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Could not load Hugging Face token from Colab secrets.\n",
            "Token数\n",
            " - Positive : 43\n",
            " - Negative : 2\n",
            " - multiple : 1\n",
            "https://civitai.com/api/download/models/1410435?type=Model&format=SafeTensor&size=pruned&fp=fp16\n",
            "Downloading Checkpoint model to /content/models/downloaded_model.safetensors...\n",
            "--2025-09-29 23:40:10--  https://civitai.com/api/download/models/1410435?type=Model&format=SafeTensor&size=pruned&fp=fp16\n",
            "Resolving civitai.com (civitai.com)... 172.66.152.186, 104.20.38.219, 2606:4700:10::ac42:98ba, ...\n",
            "Connecting to civitai.com (civitai.com)|172.66.152.186|:443... connected.\n",
            "HTTP request sent, awaiting response... "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2371384491.py:347: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  jst = datetime.utcnow() + timedelta(hours=9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "307 Temporary Redirect\n",
            "Location: https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/31176/waiNsfwIllustrious11.Nmu2.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22waiNSFWIllustrious_v110.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250929/us-east-1/s3/aws4_request&X-Amz-Date=20250929T234010Z&X-Amz-SignedHeaders=host&X-Amz-Signature=cf09223f12eb9cac6ea2b4d0a6453a0135ee590c5e249ca7a8812e4c4797b76d [following]\n",
            "--2025-09-29 23:40:11--  https://civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com/model/31176/waiNsfwIllustrious11.Nmu2.safetensors?X-Amz-Expires=86400&response-content-disposition=attachment%3B%20filename%3D%22waiNSFWIllustrious_v110.safetensors%22&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=e01358d793ad6966166af8b3064953ad/20250929/us-east-1/s3/aws4_request&X-Amz-Date=20250929T234010Z&X-Amz-SignedHeaders=host&X-Amz-Signature=cf09223f12eb9cac6ea2b4d0a6453a0135ee590c5e249ca7a8812e4c4797b76d\n",
            "Resolving civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)... 172.64.66.1, 2606:4700:2ff9::1\n",
            "Connecting to civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com (civitai-delivery-worker-prod.5ac0637cfd0766c97916cefa3764fbdf.r2.cloudflarestorage.com)|172.64.66.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6938040682 (6.5G)\n",
            "Saving to: ‘/content/models/downloaded_model.safetensors’\n",
            "\n",
            "/content/models/dow 100%[===================>]   6.46G  51.8MB/s    in 3m 19s  \n",
            "\n",
            "2025-09-29 23:43:30 (33.3 MB/s) - ‘/content/models/downloaded_model.safetensors’ saved [6938040682/6938040682]\n",
            "\n",
            "Download of safetensorFile complete!\n",
            "Downloading LoRA model to /content/models/1709991...\n",
            "Error downloading LoRA file: 401 Client Error: Unauthorized for url: https://civitai.com/api/download/models/1709991?type=Model&format=SafeTensor\n",
            "--2025-09-29 23:43:30--  https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1873 (1.8K) [text/plain]\n",
            "Saving to: ‘/content/models/v1-inference.yaml’\n",
            "\n",
            "/content/models/v1- 100%[===================>]   1.83K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-09-29 23:43:30 (36.1 MB/s) - ‘/content/models/v1-inference.yaml’ saved [1873/1873]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 17 files:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "94024bfa64e14908a1ff5a59a1df94ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28673ebfa2dc4ee58fd4a840b0b76394"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "359ae9d616344197967347bed899a22f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 60.12 MiB is free. Process 3805 has 14.68 GiB memory in use. Of the allocated memory 13.99 GiB is allocated by PyTorch, and 571.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2371384491.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    492\u001b[0m   \u001b[0;31m#pipe.enable_xformers_memory_efficient_attention()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcivitai_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m       image = pipe_civitai(prompt=civitai_params[\"positive_prompt\"],\n\u001b[0m\u001b[1;32m    495\u001b[0m           \u001b[0mnegative_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcivitai_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"negative_prompt\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m           \u001b[0mnum_inference_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcivitai_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"steps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, prompt_2, height, width, num_inference_steps, timesteps, sigmas, denoising_end, guidance_scale, negative_prompt, negative_prompt_2, num_images_per_prompt, eta, generator, latents, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, ip_adapter_image, ip_adapter_image_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, original_size, crops_coords_top_left, target_size, negative_original_size, negative_crops_coords_top_left, negative_target_size, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1290\u001b[0m                 \u001b[0mlatents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatents\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaling_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;31m# cast back to fp16 if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/utils/accelerate_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_hf_hook\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pre_forward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hf_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/models/autoencoders/autoencoder_kl.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, z, return_dict, generator)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded_slices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/models/autoencoders/autoencoder_kl.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, z, return_dict)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_quant_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/models/autoencoders/vae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sample, latent_embeds)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0;31m# up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mup_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mup_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_embeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# post-process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/models/unets/unet_2d_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, temb)\u001b[0m\n\u001b[1;32m   2641\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsamplers\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2642\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mupsampler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsamplers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2643\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupsampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2645\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/diffusers/models/upsampling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, output_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_conv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"conv\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    541\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             )\n\u001b[0;32m--> 543\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    544\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 384.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 60.12 MiB is free. Process 3805 has 14.68 GiB memory in use. Of the allocated memory 13.99 GiB is allocated by PyTorch, and 571.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title LogInが必要な場合に、modelをダウンロードするコード(実行後は\"origin\"からスタート)。\n",
        "#@markdown CivitAIでAPIキーを生成(名前はなんでもいい)して、secretにCIVITAI_APIという名前でvalueにtoken追加して。\n",
        "\n",
        "# Colab 用：CivitAI ダウンロード（SafeTensor, fp16 など）\n",
        "# インデントは 2 スペースに統一しています。\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- 設定 (ここを編集) ---\n",
        "TOKEN_NAME = \"CIVITAI_API\" #@param {type:\"string\"}\n",
        "DOWNLOAD_URL = \"https://civitai.com/api/download/models/2167369?type=Model&format=SafeTensor&size=pruned&fp=fp16\" #@param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/Colab Notebooks/share_dir/AI_IMG/model/WAI-NSFW-illustrious-SDXL/v15-0\" #@param {type:\"string\"}\n",
        "OUTPUT_FILE = \"downloaded_model.safetensors\" #@param {type:\"string\"}\n",
        "USE_API_KEY = True #@param {type:\"boolean\"}\n",
        "# -------------------------\n",
        "\n",
        "OUTPUT_DIR = Path(OUTPUT_DIR)\n",
        "OUTPUT_FILE = OUTPUT_DIR / OUTPUT_FILE\n",
        "\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "headers = {\n",
        "  \"User-Agent\": \"colab-civitai-downloader/1.0\"\n",
        "}\n",
        "\n",
        "if USE_API_KEY:\n",
        "  try:\n",
        "    api_key = userdata.get(TOKEN_NAME)\n",
        "    headers[\"Authorization\"] = f\"Bearer {api_key}\"\n",
        "  except:\n",
        "    print(f\"Warning: Could not load API key from Colab secrets with name '{TOKEN_NAME}'. Proceeding without API key.\")\n",
        "\n",
        "\n",
        "print(\"ダウンロードを開始します。URL:\", DOWNLOAD_URL)\n",
        "\n",
        "with requests.get(DOWNLOAD_URL, headers=headers, stream=True, allow_redirects=True, timeout=60) as r:\n",
        "  status = r.status_code\n",
        "  if status == 401 or status == 403:\n",
        "    raise SystemExit(f\"認証エラー: HTTP {status} — APIキーの権限または形式を確認してください。\")\n",
        "  if status == 404:\n",
        "    raise SystemExit(\"ファイルが見つかりません: HTTP 404。モデルの存在やアクセス権を確認してください。\")\n",
        "  if status >= 500:\n",
        "    raise SystemExit(f\"サーバーエラー: HTTP {status}。時間をおいて再試行してください。\")\n",
        "\n",
        "  total = int(r.headers.get(\"Content-Length\", 0))\n",
        "  chunk_size = 8192\n",
        "\n",
        "  print(f\"保存先: {OUTPUT_FILE} (推定サイズ: {total} bytes)\")\n",
        "\n",
        "  with open(OUTPUT_FILE, \"wb\") as f, tqdm(total=total, unit=\"B\", unit_scale=True, desc=\"downloaded_model.safetensors\", ncols=80) as pbar:\n",
        "    for chunk in r.iter_content(chunk_size=chunk_size):\n",
        "      if chunk:\n",
        "        f.write(chunk)\n",
        "        pbar.update(len(chunk))\n",
        "\n",
        "print(\"ダウンロード完了:\", OUTPUT_FILE)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Iqbh5EoOuOuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d1e5811-0213-463e-c517-8b2f46e9bb0c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ダウンロードを開始します。URL: https://civitai.com/api/download/models/2167369?type=Model&format=SafeTensor&size=pruned&fp=fp16\n",
            "保存先: /content/drive/MyDrive/Colab Notebooks/share_dir/AI_IMG/model/WAI-NSFW-illustrious-SDXL/v15-0/downloaded_model.safetensors (推定サイズ: 6938040682 bytes)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "downloaded_model.safetensors: 100%|████████| 6.94G/6.94G [02:01<00:00, 57.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ダウンロード完了: /content/drive/MyDrive/Colab Notebooks/share_dir/AI_IMG/model/WAI-NSFW-illustrious-SDXL/v15-0/downloaded_model.safetensors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}
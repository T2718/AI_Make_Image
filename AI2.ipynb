{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T2718/AI_Make_Image/blob/main/AI2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QQD6GeyqR0cJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSZ_ciIF64TD",
        "outputId": "803b7aa4-3ce9-463c-b0a6-c5fd7674e11b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jax[cuda12_pip]==0.4.23\n",
            "  Downloading jax-0.4.23-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (1.11.4)\n",
            "Collecting jaxlib==0.4.23+cuda12.cudnn89 (from jax[cuda12_pip]==0.4.23)\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.23%2Bcuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl (131.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12>=12.2.5.6 (from jax[cuda12_pip]==0.4.23)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12>=12.2.142 (from jax[cuda12_pip]==0.4.23)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvcc-cu12>=12.2.140 (from jax[cuda12_pip]==0.4.23)\n",
            "  Downloading nvidia_cuda_nvcc_cu12-12.4.131-py3-none-manylinux2014_x86_64.whl (22.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12>=12.2.140 (from jax[cuda12_pip]==0.4.23)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12>=8.9 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (8.9.2.26)\n",
            "Collecting nvidia-cufft-cu12>=11.0.8.103 (from jax[cuda12_pip]==0.4.23)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12>=11.5.2 (from jax[cuda12_pip]==0.4.23)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12>=12.1.2.141 (from jax[cuda12_pip]==0.4.23)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12>=2.18.3 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.2 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.23) (12.4.127)\n",
            "Installing collected packages: nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvcc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, jaxlib, jax\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.26+cuda12.cudnn89\n",
            "    Uninstalling jaxlib-0.4.26+cuda12.cudnn89:\n",
            "      Successfully uninstalled jaxlib-0.4.26+cuda12.cudnn89\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.26\n",
            "    Uninstalling jax-0.4.26:\n",
            "      Successfully uninstalled jax-0.4.26\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.2.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.4.5.8 which is incompatible.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.4.127 which is incompatible.\n",
            "torch 2.2.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.4.127 which is incompatible.\n",
            "torch 2.2.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.1.3 which is incompatible.\n",
            "torch 2.2.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.1.9 which is incompatible.\n",
            "torch 2.2.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.3.1.170 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.4.23 jaxlib-0.4.23+cuda12.cudnn89 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvcc-cu12-12.4.131 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cufft-cu12-11.2.1.3 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "jax",
                  "jaxlib"
                ]
              },
              "id": "e9afb30c944e4999859b22ce1b8126b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diffusers is not imported\n",
            "Requirement already satisfied: diffusers==0.8.0 in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (6.2.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (2.31.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.8.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.8.0) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.8.0) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.8.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.8.0) (2024.2.2)\n",
            "torch was imported\n"
          ]
        }
      ],
      "source": [
        "#　画像出力のディレクトリ\n",
        "\n",
        "# 画像のファイル名\n",
        "import re\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "!pip install \"jax[cuda12_pip]==0.4.23\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
        "\n",
        "\n",
        "if \"diffusers\" in sys.modules:\n",
        "  print(\"diffusers was imported\")\n",
        "else:\n",
        "  print(\"diffusers is not imported\")\n",
        "  !pip install diffusers==0.8.0 transformers scipy ftfy\n",
        "\n",
        "if \"torch\" in sys.modules:\n",
        "  print(\"torch was imported\")\n",
        "else:\n",
        "  print(\"torch is not imported\")\n",
        "  !pip install torch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "height_num = 640\n",
        "width_num = 360\n",
        "\n",
        "model_id = \"stablediffusionapi/anything-v5\"\n",
        "\n",
        "model_list = ['stablediffusionapi/anything-v5','Oscarguid/DivineEleganceMixV9']\n",
        "\n",
        "while True:\n",
        "  setting = input('Setting用(無入力でいい):')\n",
        "  if setting == \"\":\n",
        "    print('model_id:'+model_id)\n",
        "    break\n",
        "  if setting == \"model_id\":\n",
        "    model_id = input('Kind:')\n",
        "    pre_kind = \"\"\n",
        "\n",
        "  if setting == \"model_select\":\n",
        "    for k in range(len(model_list)):\n",
        "      print(str(k)+':'+model_list[k])\n",
        "    model_id = model_list[int(input('Kind:'))]\n",
        "\n",
        "\n",
        "prompt = input('Prompt:')\n",
        "n_prompt = input('Negative_prompt:')\n",
        "strong = int(input('Strong:'))\n",
        "kind = input('画像を使用するか(T or F)\\n(Tの場合は、outputfileディレクトリのあるところと同じ階層に、\\ninput.pngで保存してください。)\\n→:')\n",
        "if(kind == 'T'):\n",
        "  image_strength = float(input('image_Strength:'))\n",
        "  init_image = Image.open('input.png').convert('RGB')\n",
        "  size_max_multi = max(init_image.width/width_num,init_image.height/height_num)\n",
        "  init_image = init_image.resize((int(init_image.width/size_max_multi),int(init_image.height/size_max_multi)))\n",
        "  print('Multi:'+str(size_max_multi))\n",
        "  #init_image\n",
        "  #print(init_image)\n",
        "\n",
        "\"\"\"if 'model' in locals():\n",
        "  print('Model was defined')\n",
        "else:\n",
        "  print('Model is undefined')\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "num = int(input('Amount:'))\n",
        "image_num_onetime = int(input('Onetime Amount:'))\n",
        "\n",
        "\n",
        "\n",
        "if 'pre_kind' not in locals():\n",
        "  pre_kind = ''\n",
        "\n",
        "\n",
        "\n",
        "#model_id = 'Oscarguid/DivineEleganceMixV9'\n",
        "access_tokens = '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'\n",
        "\n",
        "if pre_kind != kind and kind == 'T':\n",
        "  print('model is begun define')\n",
        "  from diffusers import StableDiffusionPipeline,StableDiffusionImg2ImgPipeline, DPMSolverMultistepScheduler\n",
        "  import torch\n",
        "\n",
        "  # アクセストークンの設定\n",
        "  #access_tokens=\"\" # @param {type:\"string\"}\n",
        "\n",
        "  # モデルのインスタンス化\n",
        "  # stablediffusionapi/anything-v5\n",
        "  # Oscarguid/DivineEleganceMixV9\n",
        "  # andite/pastel-mix\n",
        "  #model_id = 'Oscarguid/DivineEleganceMixV9'\n",
        "\n",
        "\n",
        "\n",
        "  model = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_auth_token=access_tokens, safety_checker=None)\n",
        "  model.scheduler = DPMSolverMultistepScheduler.from_config(model.scheduler.config)\n",
        "  model.to(\"cuda\")\n",
        "  print(model)\n",
        "elif pre_kind != kind and kind == 'F':\n",
        "  print('model is begun define')\n",
        "  from diffusers import StableDiffusionPipeline\n",
        "  import torch\n",
        "  model = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=access_tokens)\n",
        "  model.to('cuda')\n",
        "\n",
        "\n",
        "pre_kind = kind\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "filename = re.sub(r'[\\\\/:*?\"<>|,]+', '', prompt).replace(' ','_')\n",
        "if len(filename) >= 20:\n",
        "  filename = filename[0:19]\n",
        "try:\n",
        "  try:\n",
        "    os.mkdir('outputfile')\n",
        "  except:\n",
        "    pass\n",
        "  os.mkdir('outputfile/'+filename)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "# 画像数\n",
        "#num\n",
        "\n",
        "def null_safety(images, **kwargs):\n",
        "    #print('NSFW')\n",
        "    return images, False\n",
        "\n",
        "\n",
        "try:\n",
        "  model.safety_checker = null_safety\n",
        "except:\n",
        "  print('error')\n",
        "\n",
        "\n",
        "for i in range(num):\n",
        "  # モデルにpromptを入力し画像生成\n",
        "  print(str(i+1)+'枚目')\n",
        "  if kind == 'T':\n",
        "    #print(init_image)\n",
        "    #print(model)\n",
        "    #if not isinstance(model, StableDiffusionImg2ImgPipeline):\n",
        "    #  print(\"Error: `model` is not of type `StableDiffusionImg2ImgPipeline`. Please make sure you have loaded the correct model.\")\n",
        "    \"\"\"if \"image\" not in model.__call__.__kwdefaults__:\n",
        "      print(\"Error: The `image` argument is missing from the `model` function. Please make sure you are using the correct version of the `diffusers` library.\")\n",
        "    \"\"\"\n",
        "    image = model(prompt,height=height_num,width=width_num,negative_prompt=n_prompt,init_image=init_image,strength=image_strength,num_inference_steps=strong-1,num_images_per_prompt=image_num_onetime)\n",
        "  else:\n",
        "    image = model(prompt,height=height_num,width=width_num,negative_prompt=n_prompt,num_inference_steps=strong-1,num_images_per_prompt=image_num_onetime)\n",
        "  #print(image.keys())\n",
        "  image_all = image['images']\n",
        "  print(str(len(image_all))+'枚')\n",
        "  count = 0\n",
        "  filename2 = f'_{i+1:02}_'\n",
        "  try:\n",
        "    os.mkdir(f\"outputfile/{filename}/{filename2}\")\n",
        "  except:\n",
        "    pass\n",
        "  for k in image_all:\n",
        "    count += 1\n",
        "    image = k\n",
        "  # 保存\n",
        "\n",
        "    image.save(f\"outputfile/{filename}/{filename2}/_{count:02}_.png\")\n",
        "\n",
        "input('Fin')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree('outputfile')"
      ],
      "metadata": {
        "id": "K9DJaEHAEPzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "metadata": {
        "id": "sz7dY1z-xcAX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
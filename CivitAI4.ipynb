{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T2718/AI_Make_Image/blob/main/CivitAI4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- モード選択 ---\n",
        "print(\"=== モード選択 ===\")\n",
        "print(\"1: Hugging Faceで画像生成\")\n",
        "print(\"2: CivitAI（モデルDL / safetensors変換）\")\n",
        "print(\"3: トークン数を数える\")\n",
        "print(\"4: 出力フォルダを削除\")\n",
        "mode = input(\"番号を入力してください: \").strip()\n",
        "\n",
        "# --- 必要なパラメータを先に全て入力 ---\n",
        "hf_params = {}\n",
        "civitai_params = {}\n",
        "\n",
        "model_list_H = ['stablediffusionapi/eleet-model',\n",
        "              'stablediffusionapi/brav6',\n",
        "              'Vsukiyaki/ShiratakiMix',\n",
        "              'stabilityai/stable-diffusion-xl-base-1.0'\n",
        "              ]\n",
        "\n",
        "model_list_C = [\"https://civitai.com/api/download/models/28100?type=Model&format=SafeTensor&size=full&fp=fp16\",\n",
        "                \"https://civitai.com/api/download/models/11812?type=Model&format=SafeTensor&size=full&fp=fp16\"\n",
        "              ]\n",
        "\n",
        "\n",
        "\n",
        "if mode == \"1\":\n",
        "  hf_params[\"model_id\"] = input(\"HuggingFaceのモデルIDを入力（例: runwayml/stable-diffusion-v1-5）: \").strip()\n",
        "  hf_params[\"submode\"] = input(\"生成モードを選択（1: text2img, 2: img2img）: \").strip()\n",
        "  hf_params[\"prompt\"] = input(\"プロンプトを入力: \").strip()\n",
        "  hf_params[\"negative_prompt\"] = input(\"ネガティブプロンプトを入力 : \").strip()\n",
        "  hf_params[\"num\"] = int(input(\"生成する画像の枚数 : \"))\n",
        "  hf_params[\"steps\"] = int(input(\"ステップ数（例: 30）: \"))\n",
        "  hf_params[\"guidance\"] = float(input(\"guidance scale（例: 7.5）: \"))\n",
        "  if hf_params[\"submode\"] == \"2\":\n",
        "    hf_params[\"strength\"] = float(input(\"strength (例: 0.75) : \"))\n",
        "    hf_params[\"image_path\"] = input(\"初期画像のパスを入力してください（img2img用）: \")\n",
        "\n",
        "elif mode == \"2\":\n",
        "  print(\"--- CivitAI モデルの状況は？ ---\")\n",
        "  print(\"1: まだ何もしていない（DLも変換もしていない）\")\n",
        "  print(\"2: safetensorsファイルのみアップロード済み（変換が必要）\")\n",
        "  print(\"3: 変換済みでそのまま使える\")\n",
        "  civitai_params[\"status\"] = input(\"番号を入力してください: \").strip()\n",
        "  #civitai_params[\"model_name\"] = input(\"保存先モデル名（例: models）: \").strip()\n",
        "  if civitai_params[\"status\"] == \"1\":\n",
        "    civitai_params[\"url\"] = input(\"CivitAIのモデル/LoRA ダウンロードURL: \").strip()\n",
        "    civitai_params[\"need_yaml\"] = input(\"v1-inference.yamlが必要ですか？ (y/n): \").strip().lower() == \"y\"\n",
        "    civitai_params[\"safetensorsName\"] = input(\"ファイル名(downloaded_model.safetensors) : \")\n",
        "    if civitai_params[\"safetensorsName\"] == \"\":\n",
        "      civitai_params[\"safetensorsName\"] = \"downloaded_model.safetensors\"\n",
        "  elif civitai_params[\"status\"] == \"2\":\n",
        "    civitai_params[\"safefile\"] = input(\"アップロード済みの .safetensors ファイル名(downloaded_model.safetensors): \").strip()\n",
        "    if civitai_params[\"safefile\"] == \"\":\n",
        "      civitai_params[\"safefile\"] = \"downloaded_model.safetensors\"\n",
        "    civitai_params[\"need_yaml\"] = input(\"v1-inference.yamlが必要ですか？ (y/n): \").strip().lower() == \"y\"\n",
        "  civitai_params[\"prompt\"] = input(\"プロンプトを入力してください: \")\n",
        "  civitai_params[\"negative_prompt\"] = input(\"ネガティブプロンプトを入力 : \").strip()\n",
        "  civitai_params[\"num\"] = int(input(\"生成する画像の枚数 : \"))\n",
        "  civitai_params[\"steps\"] = int(input(\"ステップ数（例: 30）: \"))\n",
        "\n",
        "elif mode == \"3\":\n",
        "  token_prompt = input(\"プロンプトを入力してください（トークン数確認）: \").strip()\n",
        "\n",
        "elif mode == \"4\":\n",
        "  confirm_delete = input(\"本当にoutputフォルダを削除しますか？ (y/n): \").strip().lower()\n",
        "\n",
        "# --- 必要なinstallはここで実行（全てのinput終了後） ---\n",
        "print(\"インストールを開始します...\")\n",
        "!pip install diffusers transformers accelerate safetensors\n",
        "\n",
        "# --- 各モード実行 ---\n",
        "if mode == \"1\":\n",
        "  from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline\n",
        "  from PIL import Image\n",
        "  import torch\n",
        "  import os\n",
        "  torch_dtype = torch.float16\n",
        "  if hf_params[\"submode\"] == \"1\":\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "      hf_params[\"model_id\"],\n",
        "      torch_dtype=torch.float16,\n",
        "      safety_checker=None  # Safe checkを無効に\n",
        "    )\n",
        "    pipe = pipe.to(\"cuda\")  # GPUが必要です\n",
        "  else:\n",
        "    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
        "        hf_params[\"model_id\"],\n",
        "        torch_dtype=torch.float16,\n",
        "        safety_checker=None\n",
        "    )\n",
        "    pipe = pipe.to(\"cuda\")\n",
        "  for k in range(hf_params[\"num\"]):\n",
        "    if hf_params[\"submode\"] == \"1\":\n",
        "\n",
        "      image = pipe(hf_params[\"prompt\"],\n",
        "                   negative_prompt=hf_params[\"negative_prompt\"],\n",
        "                   num_inference_steps=hf_params[\"steps\"],\n",
        "                   guidance_scale=hf_params[\"guidance\"],\n",
        "                   added_cond_kwargs={}).images[0]\n",
        "    else:\n",
        "      init_image = Image.open(hf_params[\"image_path\"]).convert(\"RGB\").resize((512, 512))\n",
        "      image = pipe(prompt=hf_params[\"prompt\"],\n",
        "                   negative_prompt=hf_params[\"negative_prompt\"],\n",
        "                   num_inference_steps=hf_params[\"steps\"],\n",
        "                   image=init_image,\n",
        "                   strength=hf_params[\"strength\"],\n",
        "                   guidance_scale=hf_params[\"guidance\"]).images[0]\n",
        "\n",
        "    os.makedirs(\"output\", exist_ok=True)\n",
        "    filename = f\"output/huggingface_result\"+str(k)+\".png\"\n",
        "    image.save(filename)\n",
        "  print(\"画像を保存しました\")\n",
        "\n",
        "elif mode == \"2\":\n",
        "  import os\n",
        "  import torch\n",
        "  import re\n",
        "  from diffusers import StableDiffusionPipeline\n",
        "\n",
        "  base_dir = \"./converted/models\"\n",
        "  print(civitai_params[\"status\"] == \"1\")\n",
        "  if civitai_params[\"status\"] == \"1\":\n",
        "    regex = r'([0-9]{5})'\n",
        "    if bool(re.match(regex, civitai_params['url'])):\n",
        "      civitai_params['url'] = 'https://civitai.com/api/download/models/'+civitai_params['url']\n",
        "    elif civitai_params['url'] == '1':\n",
        "      civitai_params['url'] = \"https://civitai.com/api/download/models/28100?type=Model&format=SafeTensor&size=full&fp=fp16\"\n",
        "    elif civitai_params['url'] == '2':\n",
        "      civitai_params['url'] = \"https://civitai.com/api/download/models/11812?type=Model&format=SafeTensor&size=full&fp=fp16\"\n",
        "\n",
        "\n",
        "    download_path = os.path.join(\"./models\", civitai_params[\"safetensorsName\"])\n",
        "\n",
        "    model_url = civitai_params[\"url\"]\n",
        "    model_name = civitai_params[\"safetensorsName\"]\n",
        "\n",
        "    print(f\"Downloading Checkpoint model to {download_path}...\")\n",
        "    !wget -O {download_path} \"{model_url}\"\n",
        "    print(f\"Download of {model_name} complete!\")\n",
        "\n",
        "    # Checkpointモデルのパスを記録\n",
        "    checkpoint_path = download_path\n",
        "    lora_path = None # LoRAはダウンロードしないのでNone\n",
        "\n",
        "    #filename = civitai_params[\"url\"].split(\"/\")[-1]\n",
        "    #filename = civitai_params[\"safetensorsName\"]\n",
        "    #base_dir = \"/content/models\"\n",
        "    #download_path = f\"{base_dir}/{filename}\"\n",
        "    #os.makedirs(base_dir, exist_ok=True)\n",
        "    #!wget -O {download_path} \"{model_url}\"\n",
        "    #!wget -q {civitai_params[\"url\"]} -O {filename}\n",
        "    if civitai_params[\"need_yaml\"]:\n",
        "      !wget -O /content/models/v1-inference.yaml \\\n",
        "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "      #!wget -q https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-inference.yaml\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "    !python convert_original_stable_diffusion_to_diffusers.py \\\n",
        "      --checkpoint_path ./models/downloaded_model.safetensors \\\n",
        "      --original_config_file ./models/v1-inference.yaml \\\n",
        "      --dump_path ./converted/diffusers_model \\\n",
        "      --from_safetensors\n",
        "\n",
        "  elif civitai_params[\"status\"] == \"2\":\n",
        "    if civitai_params[\"need_yaml\"]:\n",
        "      !wget -O /content/models/v1-inference.yaml \\\n",
        "https://raw.githubusercontent.com/CompVis/stable-diffusion/main/configs/stable-diffusion/v1-inference.yaml\n",
        "      #!wget -q https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-inference.yaml\n",
        "    !mkdir /content/converted\n",
        "    !wget -O convert_original_stable_diffusion_to_diffusers.py \\\n",
        "    https://raw.githubusercontent.com/huggingface/diffusers/main/scripts/convert_original_stable_diffusion_to_diffusers.py\n",
        "    os.makedirs(base_dir, exist_ok=True)\n",
        "    !python convert_original_stable_diffusion_to_diffusers.py \\\n",
        "      --checkpoint_path ./models/downloaded_model.safetensors \\\n",
        "      --original_config_file ./models/v1-inference.yaml \\\n",
        "      --dump_path ./converted/diffusers_model \\\n",
        "      --from_safetensors\n",
        "\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(base_dir, torch_dtype=torch.float16).to(\"cuda\")\n",
        "  pipe.enable_xformers_memory_efficient_attention()\n",
        "  for k in range(civitai_params[\"num\"]):\n",
        "    image = pipe(prompt=civitai_params[\"prompt\"], negative_prompt=civitai_params[\"negative_prompt\"], num_inference_steps=civitai_params[\"step\"]).images[0]\n",
        "    os.makedirs(\"output/\"+civitai_params[\"prompt\"][0,10], exist_ok=True)\n",
        "    image.save(\"output/\"+civitai_params[\"prompt\"][0,10]+\"/\"+str(k)+\".png\")\n",
        "  print(\"画像を保存しました: output/\"+civitai_params[\"prompt\"][0,10]+\".png\")\n",
        "\n",
        "elif mode == \"3\":\n",
        "  from transformers import CLIPTokenizer\n",
        "  tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "  tokens = tokenizer(token_prompt)[\"input_ids\"]\n",
        "  print(f\"トークン数: {len(tokens)}\")\n",
        "\n",
        "elif mode == \"4\":\n",
        "  import shutil\n",
        "  if confirm_delete == \"y\" and os.path.exists(\"output\"):\n",
        "    shutil.rmtree(\"output\")\n",
        "    print(\"outputフォルダを削除しました\")\n",
        "  else:\n",
        "    print(\"キャンセルされました\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtmjWZm4Yeqj",
        "outputId": "7298afab-3f0c-4c6e-9f71-8fe556329a9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== モード選択 ===\n",
            "1: Hugging Faceで画像生成\n",
            "2: CivitAI（モデルDL / safetensors変換）\n",
            "3: トークン数を数える\n",
            "4: 出力フォルダを削除\n"
          ]
        }
      ]
    }
  ]
}
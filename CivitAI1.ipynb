{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyM5+E1VpQsl9JGgbDFLwPp/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T2718/AI_Make_Image/blob/main/CivitAI1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHeg3MxdMOhC"
      },
      "outputs": [],
      "source": [
        "# 1. 環境構築: 必要なライブラリのインストール\n",
        "!pip install diffusers transformers accelerate safetensors xformers\n",
        "\n",
        "# 2. モデルのダウンロード (Civitaiから手動またはスクリプトで)\n",
        "# Colabのファイルシステムに直接アップロードするか、\n",
        "# !wget コマンドなどでダウンロードします。\n",
        "# 例: checkpointファイル\n",
        "# !wget -O /content/my_model.safetensors \"https://civitai.com/api/download/models/XXXXX\"\n",
        "\n",
        "# 例: LoRAファイル\n",
        "# !wget -O /content/my_lora.safetensors \"https://civitai.com/api/download/models/YYYYY\"\n",
        "\n",
        "# 3. モデルのロードとLoRAの適用\n",
        "import torch\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "\n",
        "# 使用するデバイス\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ダウンロードしたcheckpointファイルのパスを指定\n",
        "# 例えば、ダウンロードしたファイルを /content/ に保存した場合\n",
        "model_path = \"/content/models/AnimePastelDream.safetensors\" # あなたのモデルのパスに置き換えてください\n",
        "\n",
        "# safetensors形式のカスタムモデルをロードする場合\n",
        "# safety_checker=None を追加してNSFW制限を解除\n",
        "pipeline = AutoPipelineForText2Image.from_single_file(\n",
        "    model_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None # ★ここを変更: NSFW制限を解除\n",
        ")\n",
        "\n",
        "# モデルをGPUに移動\n",
        "pipeline.to(device)\n",
        "\n",
        "# LoRAの適用\n",
        "#lora_path = \"/content/my_lora.safetensors\" # あなたのLoRAのパスに置き換えてください\n",
        "# LoRAの重みを適用（スケールは調整可能）\n",
        "#pipeline.load_lora_weights(lora_path, adapter_name=\"my_custom_lora\")\n",
        "\n",
        "# XFormersの利用 (高速化)\n",
        "if torch.cuda.is_available():\n",
        "    pipeline.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "# 4. 推論（画像生成）\n",
        "prompt = \"a naked woman walking in a forest, highly detailed, realistic\" # 例としてNSFWなプロンプト\n",
        "negative_prompt = \"low quality, blurry, distorted, censored, bad anatomy\"\n",
        "\n",
        "# 推論パラメータ（必要に応じて調整）\n",
        "num_inference_steps = 30\n",
        "guidance_scale = 7.5\n",
        "\n",
        "image = pipeline(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=num_inference_steps,\n",
        "    guidance_scale=guidance_scale,\n",
        ").images[0]\n",
        "\n",
        "# 生成された画像を保存または表示\n",
        "image.save(\"generated_image.png\")\n",
        "print(\"画像が生成され、'generated_image.png' として保存されました。\")\n",
        "\n",
        "# Colabで画像を表示する場合\n",
        "from IPython.display import Image, display\n",
        "display(Image(filename='generated_image.png'))"
      ]
    },
    {
      "source": [
        "# 1. 環境構築: 必要なライブラリのインストール\n",
        "# バージョンを指定して互換性の問題を避ける\n",
        "!pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118 # CUDA 11.8を使用する場合\n",
        "!pip install diffusers==0.19.3 transformers==4.30.2 accelerate==0.21.0 safetensors==0.3.1 xformers==0.0.20\n",
        "\n",
        "# 2. モデルのダウンロード (Civitaiから手動またはスクリプトで)\n",
        "# Colabのファイルシステムに直接アップロードするか、\n",
        "# !wget コマンドなどでダウンロードします。\n",
        "# 例: checkpointファイル\n",
        "# !wget -O /content/my_model.safetensors \"https://civitai.com/api/download/models/XXXXX\"\n",
        "\n",
        "# 例: LoRAファイル\n",
        "# !wget -O /content/my_lora.safetensors \"https://civitai.com/api/download/models/YYYYY\"\n",
        "\n",
        "# 3. モデルのロードとLoRAの適用\n",
        "import torch\n",
        "from diffusers import AutoPipelineForText2Image\n",
        "\n",
        "# 使用するデバイス\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ダウンロードしたcheckpointファイルのパスを指定\n",
        "# 例えば、ダウンロードしたファイルを /content/ に保存した場合\n",
        "model_path = \"/content/models/AnimePastelDream.safetensors\" # あなたのモデルのパスに置き換えてください\n",
        "\n",
        "# safetensors形式のカスタムモデルをロードする場合\n",
        "# safety_checker=None を追加してNSFW制限を解除\n",
        "pipeline = AutoPipelineForText2Image.from_single_file(\n",
        "    model_path,\n",
        "    torch_dtype=torch.float16,\n",
        "    safety_checker=None # ★ここを変更: NSFW制限を解除\n",
        ")\n",
        "\n",
        "# モデルをGPUに移動\n",
        "pipeline.to(device)\n",
        "\n",
        "# LoRAの適用\n",
        "#lora_path = \"/content/my_lora.safetensors\" # あなたのLoRAのパスに置き換えてください\n",
        "# LoRAの重みを適用（スケールは調整可能）\n",
        "#pipeline.load_lora_weights(lora_path, adapter_name=\"my_custom_lora\")\n",
        "\n",
        "# XFormersの利用 (高速化)\n",
        "if torch.cuda.is_available():\n",
        "    pipeline.enable_xformers_memory_efficient_attention()\n",
        "\n",
        "# 4. 推論（画像生成）\n",
        "prompt = \"a naked woman walking in a forest, highly detailed, realistic\" # 例としてNSFWなプロンプト\n",
        "negative_prompt = \"low quality, blurry, distorted, censored, bad anatomy\"\n",
        "\n",
        "# 推論パラメータ（必要に応じて調整）\n",
        "num_inference_steps = 30\n",
        "guidance_scale = 7.5\n",
        "\n",
        "image = pipeline(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=num_inference_steps,\n",
        "    guidance_scale=guidance_scale,\n",
        ").images[0]\n",
        "\n",
        "# 生成された画像を保存または表示\n",
        "image.save(\"generated_image.png\")\n",
        "print(\"画像が生成され、'generated_image.png' として保存されました。\")\n",
        "\n",
        "# Colabで画像を表示する場合\n",
        "from IPython.display import Image, display\n",
        "display(Image(filename='generated_image.png'))"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "GVbwpn7RPSlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# --- 1. ダウンロード先のディレクトリ設定 ---\n",
        "base_dir = \"/content/models\" # モデルとLoRAを同じディレクトリに保存する例\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# --- 2. ユーザーにダウンロードするタイプを選択させる ---\n",
        "print(\"--- モデルダウンロードセレクター ---\")\n",
        "print(\"1. Stable Diffusion Checkpoint モデル (例: .safetensors, .ckpt)\")\n",
        "print(\"2. LoRA モデル (例: .safetensors)\")\n",
        "print(\"-----------------------------------\")\n",
        "\n",
        "download_choice = input(\"ダウンロードしたいタイプを数字で入力してください (1 または 2): \")\n",
        "\n",
        "# --- 3. 選択に応じたダウンロード処理 ---\n",
        "\n",
        "if download_choice == '1':\n",
        "    # Checkpoint モデルのダウンロード\n",
        "    print(\"\\n--- Checkpoint モデルのダウンロード ---\")\n",
        "    print(\"CivitaiでダウンロードしたいCheckpointモデルのダウンロードリンクをコピーし、ここに貼り付けてください。\")\n",
        "    print(\"例: https://civitai.com/api/download/models/12345\")\n",
        "    model_url = input(\"CheckpointモデルのダウンロードURL: \")\n",
        "\n",
        "    if model_url == '1':\n",
        "      model_url = \"https://civitai.com/api/download/models/28100?type=Model&format=SafeTensor&size=full&fp=fp16\"\n",
        "\n",
        "    # URLからファイル名を推測するか、ユーザーに入力させる\n",
        "    # 通常、CivitaiのダウンロードURLはファイル名を含まないため、手動入力が確実\n",
        "    default_filename = model_url.split('/')[-1] if '.' in model_url.split('/')[-1] else \"downloaded_model.safetensors\"\n",
        "    model_filename = input(f\"保存するファイル名を入力してください (デフォルト: {default_filename}): \")\n",
        "    if not model_filename:\n",
        "        model_filename = default_filename\n",
        "\n",
        "    download_path = os.path.join(base_dir, model_filename)\n",
        "\n",
        "    print(f\"Downloading Checkpoint model to {download_path}...\")\n",
        "    !wget -O {download_path} \"{model_url}\"\n",
        "    print(f\"Download of {model_filename} complete!\")\n",
        "\n",
        "    # Checkpointモデルのパスを記録\n",
        "    checkpoint_path = download_path\n",
        "    lora_path = None # LoRAはダウンロードしないのでNone\n",
        "\n",
        "elif download_choice == '2':\n",
        "    # LoRA モデルのダウンロード\n",
        "    print(\"\\n--- LoRA モデルのダウンロード ---\")\n",
        "    print(\"CivitaiでダウンロードしたいLoRAモデルのダウンロードリンクをコピーし、ここに貼り付けてください。\")\n",
        "    print(\"例: https://civitai.com/api/download/models/98765\")\n",
        "    lora_url = input(\"LoRAモデルのダウンロードURL: \")\n",
        "\n",
        "    # URLからファイル名を推測するか、ユーザーに入力させる\n",
        "    default_filename = lora_url.split('/')[-1] if '.' in lora_url.split('/')[-1] else \"downloaded_lora.safetensors\"\n",
        "    lora_filename = input(f\"保存するファイル名を入力してください (デフォルト: {default_filename}): \")\n",
        "    if not lora_filename:\n",
        "        lora_filename = default_filename\n",
        "\n",
        "    download_path = os.path.join(base_dir, lora_filename)\n",
        "\n",
        "    print(f\"Downloading LoRA model to {download_path}...\")\n",
        "    !wget -O {download_path} \"{lora_url}\"\n",
        "    print(f\"Download of {lora_filename} complete!\")\n",
        "\n",
        "    # LoRAモデルのパスを記録\n",
        "    lora_path = download_path\n",
        "    checkpoint_path = None # CheckpointはダウンロードしないのでNone\n",
        "\n",
        "else:\n",
        "    print(\"無効な選択です。1 または 2 を入力してください。\")\n",
        "    checkpoint_path = None\n",
        "    lora_path = None\n",
        "\n",
        "print(\"\\n--- ダウンロード結果 ---\")\n",
        "if checkpoint_path:\n",
        "    print(f\"Checkpoint Path: {checkpoint_path}\")\n",
        "elif lora_path:\n",
        "    print(f\"LoRA Path: {lora_path}\")\n",
        "else:\n",
        "    print(\"モデルはダウンロードされませんでした。\")\n",
        "\n",
        "# --- この後、diffusersのパイプラインにダウンロードしたパスを渡す ---\n",
        "# 例:\n",
        "# if checkpoint_path:\n",
        "#     pipeline = AutoPipelineForText2Image.from_single_file(checkpoint_path, ...)\n",
        "# if lora_path:\n",
        "#     # base_model_path は別途ロードする必要がある\n",
        "#     # pipeline.load_lora_weights(lora_path, ...)"
      ],
      "metadata": {
        "id": "VPETwQATNm3r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
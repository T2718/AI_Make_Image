{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOfsiz0AK3uo2yNHQ9w5CyY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T2718/AI_Make_Image/blob/main/AI_inpaint.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#マスク作成\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# ----------- 変数定義 -----------\n",
        "path = \"/content/10.png\"\n",
        "w, h = 1024, 768  # 出力サイズ\n",
        "# --------------------------------\n",
        "\n",
        "# 元画像読み込み\n",
        "img = Image.open(path).convert(\"RGB\")\n",
        "w0, h0 = img.size\n",
        "rw, rh = w / w0, h / h0\n",
        "\n",
        "# サイズに応じてリサイズ＆パディング\n",
        "if rw < rh:\n",
        "  new_w = w\n",
        "  new_h = int(h0 * rw)\n",
        "  resized = img.resize((new_w, new_h), resample=Image.LANCZOS)\n",
        "  pad_top = (h - new_h) // 2\n",
        "  pad_bottom = h - new_h - pad_top\n",
        "  pad = (0, pad_top, 0, pad_bottom)\n",
        "else:\n",
        "  new_h = h\n",
        "  new_w = int(w0 * rh)\n",
        "  resized = img.resize((new_w, new_h), resample=Image.LANCZOS)\n",
        "  pad_left = (w - new_w) // 2\n",
        "  pad_right = w - new_w - pad_left\n",
        "  pad = (pad_left, 0, pad_right, 0)\n",
        "\n",
        "# 余白追加済み画像の生成\n",
        "image = ImageOps.expand(resized, border=pad, fill=(255, 255, 255))\n",
        "\n",
        "# マスク画像（余白のみ白、他は黒）\n",
        "mask = Image.new(\"L\", (w, h), color=255)\n",
        "mask.paste(0, box=(pad[0], pad[1], w - pad[2], h - pad[3]))\n",
        "\n",
        "# 保存\n",
        "!mkdir \"/content/gen\"\n",
        "image.save(\"gen/padded_image.png\")\n",
        "mask.save(\"gen/mask_image.png\")"
      ],
      "metadata": {
        "id": "W_CAe3Ug3rzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers accelerate\n",
        "from diffusers import StableDiffusionControlNetInpaintPipeline, ControlNetModel\n",
        "from diffusers.utils import load_image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "init_image = load_image(\n",
        "    #\"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main/stable_diffusion_inpaint/boy.png\"\n",
        "  \"/content/gen/padded_image.png\"\n",
        ")\n",
        "init_image = init_image.resize((512, 512))\n",
        "\n",
        "generator = torch.Generator(device=\"cpu\").manual_seed(1)\n",
        "\n",
        "mask_image = load_image(\n",
        "    #\"https://huggingface.co/datasets/diffusers/test-arrays/resolve/main/stable_diffusion_inpaint/boy_mask.png\"\n",
        "  \"/content/gen/mask_image.png\"\n",
        ")\n",
        "mask_image = mask_image.resize((512, 512))\n",
        "\n",
        "\n",
        "def make_inpaint_condition(image, image_mask):\n",
        "    image = np.array(image.convert(\"RGB\")).astype(np.float32) / 255.0\n",
        "    image_mask = np.array(image_mask.convert(\"L\")).astype(np.float32) / 255.0\n",
        "\n",
        "    assert image.shape[0:1] == image_mask.shape[0:1], \"image and image_mask must have the same image size\"\n",
        "    image[image_mask > 0.5] = -1.0  # set as masked pixel\n",
        "    image = np.expand_dims(image, 0).transpose(0, 3, 1, 2)\n",
        "    image = torch.from_numpy(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "control_image = make_inpaint_condition(init_image, mask_image)\n",
        "\n",
        "controlnet = ControlNetModel.from_pretrained(\n",
        "    \"lllyasviel/control_v11p_sd15_inpaint\", torch_dtype=torch.float16\n",
        ")\n",
        "\"\"\"pipe = StableDiffusionControlNetInpaintPipeline.from_pretrained(\n",
        "  \"runwayml/stable-diffusion-v1-5\", controlnet=controlnet, torch_dtype=torch.float16,\n",
        "  safety_checker=None,\n",
        ")\n",
        "\n",
        "#pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
        "pipe.enable_model_cpu_offload()\n",
        "\"\"\"\n",
        "\n",
        "prompt = \"anime, colorful cloak, 1girl, floating, golden fox ears, golden long hair, elegant face, gentle smile, modest dress, natural fingers, starlit sky, magical glow, colorful light particles, soft rainbow haze, aurora sky, bluish shadows, faint magenta glow, delicate warm light\"\n",
        "\n",
        "# generate image\n",
        "image = pipe(\n",
        "    prompt,\n",
        "    num_inference_steps=100,\n",
        "    generator=generator,\n",
        "    eta=1.0,\n",
        "    image=init_image,\n",
        "    mask_image=mask_image,\n",
        "    control_image=control_image,\n",
        "\n",
        ").images[0]\n",
        "\n",
        "#pipe.safety_checker = lambda images, **kwargs: (images, [False] * len(images))\n",
        "\n",
        "image.save(\"output.png\")"
      ],
      "metadata": {
        "id": "oXpJXatO1VkU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
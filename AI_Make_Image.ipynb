{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T2718/AI_Make_Image/blob/main/AI_Make_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QQD6GeyqR0cJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSZ_ciIF64TD",
        "outputId": "8e1b1968-6f0b-4979-e51f-1aac47508de1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diffusers is not imported\n",
            "Collecting diffusers==0.8.0\n",
            "  Using cached diffusers-0.8.0-py3-none-any.whl (433 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Collecting ftfy\n",
            "  Using cached ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (7.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (2.31.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.8.0) (9.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy) (0.2.13)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.8.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.10.0->diffusers==0.8.0) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.8.0) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.8.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.8.0) (2024.2.2)\n",
            "Installing collected packages: ftfy, diffusers\n",
            "Successfully installed diffusers-0.8.0 ftfy-6.2.0\n",
            "torch is not imported\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.7/196.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:28\u001b[0m"
          ]
        }
      ],
      "source": [
        "#　画像出力のディレクトリ\n",
        "\n",
        "# 画像のファイル名\n",
        "import re\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "\n",
        "if \"diffusers\" in sys.modules:\n",
        "  print(\"diffusers was imported\")\n",
        "else:\n",
        "  print(\"diffusers is not imported\")\n",
        "  !pip install diffusers==0.8.0 transformers scipy ftfy\n",
        "\n",
        "if \"torch\" in sys.modules:\n",
        "  print(\"torch was imported\")\n",
        "else:\n",
        "  print(\"torch is not imported\")\n",
        "  !pip install torch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "height_num = 640\n",
        "width_num = 360\n",
        "\n",
        "prompt = input('Prompt:')\n",
        "n_prompt = input('Negative_prompt:')\n",
        "strong = int(input('Strong:'))\n",
        "kind = input('画像を使用するか(T or F)\\n(Tの場合は、outputfileディレクトリのあるところと同じ階層に、\\ninput.pngで保存してください。)\\n→:')\n",
        "if(kind == 'T'):\n",
        "  image_strength = float(input('image_Strength:'))\n",
        "  init_image = Image.open('input.png').convert('RGB')\n",
        "  #init_image\n",
        "  #print(init_image)\n",
        "\n",
        "\"\"\"if 'model' in locals():\n",
        "  print('Model was defined')\n",
        "else:\n",
        "  print('Model is undefined')\"\"\"\n",
        "\n",
        "\n",
        "if 'pre_kind' not in locals():\n",
        "  pre_kind = ''\n",
        "\n",
        "\n",
        "\n",
        "model_id = 'Oscarguid/DivineEleganceMixV9'\n",
        "access_tokens = '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'\n",
        "\n",
        "if pre_kind != kind and kind == 'T':\n",
        "  from diffusers import StableDiffusionPipeline,StableDiffusionImg2ImgPipeline, DPMSolverMultistepScheduler\n",
        "  import torch\n",
        "\n",
        "  # アクセストークンの設定\n",
        "  #access_tokens=\"\" # @param {type:\"string\"}\n",
        "\n",
        "  # モデルのインスタンス化\n",
        "  # stablediffusionapi/anything-v5\n",
        "  # Oscarguid/DivineEleganceMixV9\n",
        "  # andite/pastel-mix\n",
        "  #model_id = 'Oscarguid/DivineEleganceMixV9'\n",
        "\n",
        "\n",
        "\n",
        "  model = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, torch_dtype=torch.float16, use_auth_token=access_tokens, safety_checker=None)\n",
        "  model.scheduler = DPMSolverMultistepScheduler.from_config(model.scheduler.config)\n",
        "  model.to(\"cuda\")\n",
        "  print(model)\n",
        "elif pre_kind != kind and kind == 'F':\n",
        "  model = StableDiffusionPipeline.from_pretrained(model_id, use_auth_token=access_tokens)\n",
        "  model.to('cuda')\n",
        "\n",
        "\n",
        "pre_kind = kind\n",
        "\n",
        "num = int(input('Amount:'))\n",
        "image_num_onetime = int(input('Onetime Amount:'))\n",
        "filename = re.sub(r'[\\\\/:*?\"<>|,]+', '', prompt).replace(' ','_')\n",
        "if len(filename) >= 20:\n",
        "  filename = filename[0:19]\n",
        "try:\n",
        "  try:\n",
        "    os.mkdir('outputfile')\n",
        "  except:\n",
        "    pass\n",
        "  os.mkdir('outputfile/'+filename)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "# 画像数\n",
        "#num\n",
        "\n",
        "def null_safety(images, **kwargs):\n",
        "    #print('NSFW')\n",
        "    return images, False\n",
        "\n",
        "\n",
        "try:\n",
        "  model.safety_checker = null_safety\n",
        "except:\n",
        "  print('error')\n",
        "\n",
        "\n",
        "for i in range(num):\n",
        "  # モデルにpromptを入力し画像生成\n",
        "  print(str(i+1)+'枚目')\n",
        "  if kind == 'T':\n",
        "    #print(init_image)\n",
        "    #print(model)\n",
        "    #if not isinstance(model, StableDiffusionImg2ImgPipeline):\n",
        "    #  print(\"Error: `model` is not of type `StableDiffusionImg2ImgPipeline`. Please make sure you have loaded the correct model.\")\n",
        "    \"\"\"if \"image\" not in model.__call__.__kwdefaults__:\n",
        "      print(\"Error: The `image` argument is missing from the `model` function. Please make sure you are using the correct version of the `diffusers` library.\")\n",
        "    \"\"\"\n",
        "    image = model(prompt,height=height_num,width=width_num,negative_prompt=n_prompt,init_image=init_image,strength=image_strength,num_inference_steps=strong-1,num_images_per_prompt=image_num_onetime)\n",
        "  else:\n",
        "    image = model(prompt,height=height_num,width=width_num,negative_prompt=n_prompt,num_inference_steps=strong-1,num_images_per_prompt=image_num_onetime)\n",
        "  #print(image.keys())\n",
        "  image_all = image['images']\n",
        "  print(str(len(image_all))+'枚')\n",
        "  count = 0\n",
        "  filename2 = f'_{i+1:02}_'\n",
        "  try:\n",
        "    os.mkdir(f\"outputfile/{filename}/{filename2}\")\n",
        "  except:\n",
        "    pass\n",
        "  for k in image_all:\n",
        "    count += 1\n",
        "    image = k\n",
        "  # 保存\n",
        "\n",
        "    image.save(f\"outputfile/{filename}/{filename2}/_{count:02}_.png\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.rmtree('outputfile')"
      ],
      "metadata": {
        "id": "K9DJaEHAEPzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "metadata": {
        "id": "sz7dY1z-xcAX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
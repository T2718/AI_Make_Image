{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/T2718/AI_Make_Image/blob/main/AI_Make_Image.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QQD6GeyqR0cJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IF83GoDH7z1h"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!pip install diffusers==0.8.0 transformers scipy ftfy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "# アクセストークンの設定\n",
        "access_tokens=\"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\" # @param {type:\"string\"}\n",
        "\n",
        "# モデルのインスタンス化\n",
        "# stablediffusionapi/anything-v5\n",
        "# Oscarguid/DivineEleganceMixV9\n",
        "# andite/pastel-mix\n",
        "model = StableDiffusionPipeline.from_pretrained(\"Oscarguid/DivineEleganceMixV9\", use_auth_token=access_tokens)\n",
        "model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "95OubKq-MCb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "ZU_aGdARH5pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSZ_ciIF64TD"
      },
      "outputs": [],
      "source": [
        "#　画像出力のディレクトリ\n",
        "\n",
        "# 画像のファイル名\n",
        "import re\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "prompt = input('Prompt:')\n",
        "n_prompt = input('Negative_prompt')\n",
        "strong = int(input('Strong:'))\n",
        "kind = input('画像を使用するか(T or F)\\n(Tの場合は、outputfileディレクトリのあるところと同じ階層に、\\ninput.pngで保存してください。)\\n→:')\n",
        "if(kind == 'T'):\n",
        "  init_image = Image.open('input.png')\n",
        "  init_image\n",
        "  image_strength = float(input('image_Strength:'))\n",
        "\n",
        "\n",
        "num = int(input('Amount:'))\n",
        "image_num_onetime = int(input('Onetime Amount:'))\n",
        "filename = re.sub(r'[\\\\/:*?\"<>|,]+', '', prompt).replace(' ','_')\n",
        "if len(filename) >= 20:\n",
        "  filename = filename[0:19]\n",
        "try:\n",
        "  try:\n",
        "    os.mkdir('outputfile')\n",
        "  except:\n",
        "    pass\n",
        "  os.mkdir('outputfile/'+filename)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "\n",
        "# 画像数\n",
        "#num\n",
        "\n",
        "def null_safety(images, **kwargs):\n",
        "    print('NSFW')\n",
        "    return images, False\n",
        "\n",
        "\n",
        "try:\n",
        "  model.safety_checker = null_safety\n",
        "except:\n",
        "  print('error')\n",
        "\n",
        "\n",
        "for i in range(num):\n",
        "  # モデルにpromptを入力し画像生成\n",
        "  if kind == 'T':\n",
        "    image = model(prompt,negative_prompt=n_prompt,image=init_image,strength=image_strength,num_inference_steps=strong-1,num_images_per_prompt=image_num_onetime)\n",
        "  else:\n",
        "    image = model(prompt,negative_primpt=n_prompt,num_inference_steps=strong-1,num_images_per_prompt=image_num_onetime)\n",
        "  #print(image.keys())\n",
        "  image_all = image['images']\n",
        "  print(str(len(image_all))+'枚')\n",
        "  count = 0\n",
        "  filename2 = f'_{i:02}_'\n",
        "  try:\n",
        "    os.mkdir(f\"outputfile/{filename}/{filename2}\")\n",
        "  except:\n",
        "    pass\n",
        "  for k in image_all:\n",
        "    count += 1\n",
        "    image = k\n",
        "  # 保存\n",
        "\n",
        "    image.save(f\"outputfile/{filename}/{filename2}/_{count:02}_.png\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf outputfile"
      ],
      "metadata": {
        "id": "0-ILDfP-MpNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "metadata": {
        "id": "sz7dY1z-xcAX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}